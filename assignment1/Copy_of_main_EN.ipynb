{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCwYnOWI0K5G"
      },
      "source": [
        "# Genetics Application\n",
        "\n",
        "For this set of questions, we will explore the use of Convolutional Neural Networks to solve a problem with Biological significance (don't worry, no background knowledge is expected). Every cell in your body contains Deoxyribonucleic acid (DNA), which is essentially the instructions for making all the proteins in your body. DNA can be thought of as a very long string where the alphabet is \\{A,C,T,G\\}.\n",
        "The physical attributes of the DNA string and its characters are not important here, except that ~98% of our DNA is physically inaccessible to external molecules. Understanding which regions of DNA are accessible and why is of great interest to scientists. This motivates learning predictive models which could accurately classify such regions. In particular, we will be implementing the deep network called [Basset](https://pubmed.ncbi.nlm.nih.gov/27197224/).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BB1odRcEQdHp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a2980df-1756-485b-8080-1d22382b5180"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "#@title Mount your Google Drive\n",
        "%matplotlib inline\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "UjZWGP-Ert-p"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Pml4PO8l0YWk"
      },
      "outputs": [],
      "source": [
        "#@title Link your assignment folder & install requirements\n",
        "#@markdown Enter the path to the assignment folder in your Google Drive\n",
        "import sys\n",
        "import os\n",
        "import shutil\n",
        "import warnings\n",
        "\n",
        "folder = \"/content/gdrive/MyDrive/IFT6135_A1_Data\" #@param {type:\"string\"}\n",
        "!ln -Ts $folder /content/IFT6135_A1_Data 2> /dev/null\n",
        "\n",
        "# Add the assignment folder to Python path\n",
        "if '/content/IFT6135_A1_Data' not in sys.path:\n",
        "    sys.path.insert(0, '/content/IFT6135_A1_Data')\n",
        "\n",
        "# Install requirements\n",
        "# !pip install -qr /content/IFT6135_A1_Data/requirements.txt\n",
        "\n",
        "# Check if CUDA is available\n",
        "import torch\n",
        "if not torch.cuda.is_available():\n",
        "    warnings.warn('CUDA is not available.')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/gdrive/MyDrive/IFT6135_A1_Data/er.zip\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpM5Wr5XqWjt",
        "outputId": "15b5a978-7bd0-4964-ce2b-8084e978dde9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/gdrive/MyDrive/IFT6135_A1_Data/er.zip\n",
            "  inflating: er.h5                   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "dtoPVSqz48lX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "653f32bd-caae-4a1f-c6c1-d8513c713a66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "# unzip data\n",
        "if not os.path.exists('/content/A1/er.h5'):\n",
        "    os.system('unzip /content/A1/er.zip')\n",
        "    os.system('mv /content/er.h5 /content/A1/er.h5')\n",
        "    print(\"done\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists('/content/A1/er.h5'):\n",
        "  print(\"S\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwAiaHNwnu8y",
        "outputId": "d188f77b-4fcd-4ba0-80ec-a7cae9ef225c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzCmch4U1nn7"
      },
      "source": [
        "## Running on GPU\n",
        "In Google Colab, you can run your code on GPU. This will be particularly important in CNN part of the assignment. To make sure the notebook is running on GPU, you can change the notebook settings with\n",
        "* (EN) `Edit > Notebook Settings`\n",
        "* (FR) `Modifier > Paramètres du notebook`\n",
        "\n",
        "Be mindful not to use the GPU if your code does not need to run on GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "sdRulajo1yNM"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import h5py\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "\n",
        "# import solution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "S1Fl3O998HzR"
      },
      "outputs": [],
      "source": [
        "# The hyperparameters we will use\n",
        "batch_size = 64\n",
        "learning_rate = 0.002"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "FJhundfW8OAK"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# set RNG\n",
        "seed = 42\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "if device.type=='cuda':\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device.type"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "00oKqVYFenb_",
        "outputId": "a9d0f504-5c7c-4310-9d0a-116725b70450"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cuda'"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dzm7-Yyk7X8z"
      },
      "source": [
        "Let's build the dataset that we will be using. Before doing any machine learning, you should always inspect the data you will be using (especially when that data is uncommon)!\n",
        "\n",
        "In our case, the input data are subsequences of DNA that come from the reference human genome HG19. HG19 can be thought of as the DNA of a prototypical human (but it does not come from any single person).\n",
        "The input data is one-hot encoded, such that:\n",
        "\n",
        "$$A = \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\\\ 0 \\end{pmatrix}, C = \\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\\\ 0 \\end{pmatrix}, G = \\begin{pmatrix} 0 \\\\ 0 \\\\ 1 \\\\ 0 \\end{pmatrix}, T = \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\\\ 1 \\end{pmatrix}$$\n",
        "\n",
        "Each base-pair $\\{A,C,G,T\\}$ are concatenated along the length of the sequence. Each data point is equivalent to an image with a rectangular shape (sequence length, 4) and a single channel for data processing purposes.\n",
        "\n",
        "The target data for our sequence are binary strings encoded as $1$ if the DNA subsequence is accessible and $0$ if it is not. This data was collected across experiments. For each sample, the target is a vector of size 164, with $1$s in the indices of the experiments where the DNA is accessible and $0$ otherwise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgU0b7Yoe0um"
      },
      "source": [
        "# **Question 1 (Understanding the Data)** \n",
        "(10 points). You will notice that PyTorch is very object-oriented -- everything you use is the subclass of a PyTorch class. For datasets, we subclass `torch.utils.data.Dataset`.\n",
        "\n",
        "1. Define the `__getitem__` and `__len__` methods for the `BassetDataset` class in `solution.py`\n",
        "2. What is the length of each sequence we will feed into our model?  Make the `get_seq_len` method of the `BassetDataset` class to return it.\n",
        "3. Is it true that each data point is also equivalent to an image with a rectangular shape (1, sequence length) with 4 channels? Write the method `is_equvalent` to return your answer (either return True or False).\n",
        "\n",
        "Note: this data has already been pre-processed, so do not include any additional data transformations!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "mDmrenF07TwY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25cd3184-328a-44b9-f862-16f35fcff9d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<KeysViewHDF5 ['target_labels', 'test_headers', 'test_in', 'test_out', 'train_in', 'train_out', 'valid_in', 'valid_out']>\n"
          ]
        }
      ],
      "source": [
        "# investigate your data\n",
        "f = h5py.File('er.h5', 'r')\n",
        "print(f.keys())\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = h5py.File('er.h5', 'r')\n",
        "\n",
        "target_labels = dataset['target_labels']\n",
        "\n",
        "split_dict = {'train': ['train_in', 'train_out'],\n",
        "                      'test': ['test_in', 'test_out'],\n",
        "                      'valid': ['valid_in', 'valid_out']}\n",
        "                      \n",
        "inputs = dataset[split_dict[\"train\"][0]]\n",
        "outputs = dataset[split_dict[\"train\"][1]]\n",
        "\n",
        "ids = list(range(len(inputs)))\n",
        "# if self.split == 'test':\n",
        "#   self.id_vars = np.char.decode(self.dataset['test_headers'])"
      ],
      "metadata": {
        "id": "Iq5DNbFF8NeC"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i = 100\n",
        "idx = ids[i]\n",
        "\n",
        "seq = inputs[idx]\n",
        "target = outputs[idx]\n",
        "print(seq.shape)\n",
        "print(seq)\n",
        "seq = np.transpose(seq, (1, 2, 0)).astype(np.float32)\n",
        "print(seq.shape)\n",
        "print(torch.Tensor(seq).shape)\n",
        "target = np.float32(target)\n",
        "output = {'sequence': torch.Tensor(seq), \n",
        "          'target': torch.Tensor(target)}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpuVs4_O8NWK",
        "outputId": "2a3fe4d3-c5f3-4686-dd40-54bec9932463"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4, 1, 600)\n",
            "[[[0. 0. 0. ... 0. 1. 0.]]\n",
            "\n",
            " [[0. 0. 0. ... 1. 0. 0.]]\n",
            "\n",
            " [[1. 0. 0. ... 0. 0. 0.]]\n",
            "\n",
            " [[0. 1. 1. ... 0. 0. 1.]]]\n",
            "(1, 600, 4)\n",
            "torch.Size([1, 600, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import h5py\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "class BassetDataset(Dataset):\n",
        "    \"\"\"\n",
        "    BassetDataset class taken with permission from Dr. Ahmad Pesaranghader\n",
        "\n",
        "    We have already processed the data in HDF5 format: er.h5\n",
        "    See https://www.h5py.org/ for details of the Python package used\n",
        "\n",
        "    We used the same data processing pipeline as the paper.\n",
        "    You can find the code here: https://github.com/davek44/Basset\n",
        "    \"\"\"\n",
        "\n",
        "    # Initializes the BassetDataset\n",
        "    def __init__(self, path='', f5name='er.h5', split='train', transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            :param path: path to HDF5 file\n",
        "            :param f5name: HDF5 file name\n",
        "            :param split: split that we are interested to work with\n",
        "            :param transform (callable, optional): Optional transform to be applied on a sample\n",
        "        \"\"\"\n",
        "\n",
        "        self.split = split\n",
        "\n",
        "        split_dict = {'train': ['train_in', 'train_out'],\n",
        "                      'test': ['test_in', 'test_out'],\n",
        "                      'valid': ['valid_in', 'valid_out']}\n",
        "\n",
        "        assert self.split in split_dict, \"'split' argument can be only defined as 'train', 'valid' or 'test'\"\n",
        "\n",
        "        # Open hdf5 file where one-hoted data are stored\n",
        "        self.dataset = h5py.File(os.path.join(path, f5name.format(self.split)), 'r')\n",
        "\n",
        "        # Keeping track of the names of the target labels\n",
        "        self.target_labels = self.dataset['target_labels']\n",
        "\n",
        "        # Get the list of volumes\n",
        "        self.inputs = self.dataset[split_dict[split][0]]\n",
        "        self.outputs = self.dataset[split_dict[split][1]]\n",
        "\n",
        "        self.ids = list(range(len(self.inputs)))\n",
        "        if self.split == 'test':\n",
        "            self.id_vars = np.char.decode(self.dataset['test_headers'])\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        \"\"\"\n",
        "        Returns the sequence and the target at index i\n",
        "\n",
        "        Notes:\n",
        "        * The data is stored as float16, however, your model will expect float32.\n",
        "          Do the type conversion here!\n",
        "        * Pay attention to the output shape of the data.\n",
        "          Change it to match what the model is expecting\n",
        "          hint: https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html\n",
        "        * The target must also be converted to float32\n",
        "        \"\"\"\n",
        "\n",
        "        idx = self.ids[i]\n",
        "        # WRITE CODE HERE\n",
        "\n",
        "        seq = self.inputs[idx]\n",
        "        target = self.outputs[idx]\n",
        "\n",
        "        seq = np.transpose(seq, (1, 2, 0)).astype(np.float32)\n",
        "        target = np.float32(target)\n",
        "        # Sequence & Target\n",
        "        output = {'sequence': torch.Tensor(seq), \n",
        "                  'target': torch.Tensor(target)}\n",
        "        return output\n",
        "\n",
        "    def __len__(self):\n",
        "        # WRITE CODE HERE\n",
        "        return len(self.inputs)\n",
        "\n",
        "    def get_seq_len(self):\n",
        "        \"\"\"\n",
        "        Answer to Q1 part 2\n",
        "        \"\"\"\n",
        "        # WRITE CODE HERE\n",
        "        return self.inputs[0].shape[-1]\n",
        "\n",
        "    def is_equivalent(self):\n",
        "        \"\"\"\n",
        "        Answer to Q1 part 3\n",
        "        \"\"\"\n",
        "        # WRITE CODE HERE\n",
        "        return True"
      ],
      "metadata": {
        "id": "yy8Yn2wulJ3t"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "v2P1XHMAMZD4"
      },
      "outputs": [],
      "source": [
        "basset_dataset_train = BassetDataset(path='', f5name='er.h5', split='train')\n",
        "basset_dataset_valid = BassetDataset(path='', f5name='er.h5', split='valid')\n",
        "basset_dataset_test = BassetDataset(path='', f5name='er.h5', split='test')\n",
        "basset_dataloader_train = DataLoader(basset_dataset_train,\n",
        "                                     batch_size=batch_size,\n",
        "                                     drop_last=True,\n",
        "                                     shuffle=True,\n",
        "                                     num_workers=1)\n",
        "basset_dataloader_valid = DataLoader(basset_dataset_valid,\n",
        "                                     batch_size=batch_size,\n",
        "                                     drop_last=True,\n",
        "                                     shuffle=False,\n",
        "                                     num_workers=1)\n",
        "basset_dataloader_test = DataLoader(basset_dataset_test,\n",
        "                                    batch_size=batch_size,\n",
        "                                    drop_last=True,\n",
        "                                    shuffle=False,\n",
        "                                    num_workers=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, sample in enumerate(basset_dataloader_test):\n",
        "  print(i)\n",
        "  print(sample)\n",
        "  print(sample[\"sequence\"].shape)\n",
        "  print(sample[\"target\"].shape)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TlPTX4WIFyXH",
        "outputId": "30d889fe-9e6b-49bd-96ef-58ef8af02758"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "{'sequence': tensor([[[[0., 1., 0., 0.],\n",
            "          [0., 0., 0., 1.],\n",
            "          [0., 1., 0., 0.],\n",
            "          ...,\n",
            "          [1., 0., 0., 0.],\n",
            "          [1., 0., 0., 0.],\n",
            "          [1., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 1., 0., 0.],\n",
            "          [0., 0., 0., 1.],\n",
            "          [0., 0., 0., 1.],\n",
            "          ...,\n",
            "          [0., 1., 0., 0.],\n",
            "          [0., 1., 0., 0.],\n",
            "          [0., 0., 0., 1.]]],\n",
            "\n",
            "\n",
            "        [[[1., 0., 0., 0.],\n",
            "          [0., 1., 0., 0.],\n",
            "          [0., 1., 0., 0.],\n",
            "          ...,\n",
            "          [1., 0., 0., 0.],\n",
            "          [0., 0., 0., 1.],\n",
            "          [1., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0., 1.],\n",
            "          [0., 0., 1., 0.],\n",
            "          [0., 0., 0., 1.],\n",
            "          ...,\n",
            "          [0., 1., 0., 0.],\n",
            "          [1., 0., 0., 0.],\n",
            "          [1., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[1., 0., 0., 0.],\n",
            "          [0., 0., 0., 1.],\n",
            "          [0., 0., 0., 1.],\n",
            "          ...,\n",
            "          [0., 1., 0., 0.],\n",
            "          [1., 0., 0., 0.],\n",
            "          [0., 0., 1., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 1., 0.],\n",
            "          [1., 0., 0., 0.],\n",
            "          [0., 1., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 1., 0.],\n",
            "          [0., 0., 0., 1.],\n",
            "          [0., 0., 1., 0.]]]]), 'target': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [1., 0., 0.,  ..., 0., 0., 0.]])}\n",
            "torch.Size([64, 1, 600, 4])\n",
            "torch.Size([64, 164])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for data in basset_dataloader_valid:\n",
        "  print(data.keys())\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8A5-sKIWeM8",
        "outputId": "d69444ba-0378-4b65-f4b0-00923f5369a6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['sequence', 'target'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFH5c18f89_Y"
      },
      "source": [
        "# **Question 2 (Building the Network)** \n",
        "(15 points). PyTorch also provides an abstraction for differentiable models: `torch.nn.Module`. In `solution.py`, we define Basset as a subclass of this class.\n",
        "\n",
        "1. Fill in the missing values denoted as `?` within the class definition using [supplementary figure 13](https://genome.cshlp.org/content/suppl/2016/06/10/gr.200535.115.DC1/Supplementary_Figures.pdf) and convolution arithmetic.\n",
        "2. Write the `forward` pass function. Again, please refer to [supplementary figure 13](https://genome.cshlp.org/content/suppl/2016/06/10/gr.200535.115.DC1/Supplementary_Figures.pdf).\n",
        "\n",
        "  Do not include any output activation in your forward method! In practice, it is better to use a loss function that has the output activation built-in."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Solution.py"
      ],
      "metadata": {
        "id": "QWUI3lKMyLNI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This script contains the helper functions you will be using for this assignment\n",
        "\n",
        "import os\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import h5py\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "class BassetDataset(Dataset):\n",
        "    \"\"\"\n",
        "    BassetDataset class taken with permission from Dr. Ahmad Pesaranghader\n",
        "\n",
        "    We have already processed the data in HDF5 format: er.h5\n",
        "    See https://www.h5py.org/ for details of the Python package used\n",
        "\n",
        "    We used the same data processing pipeline as the paper.\n",
        "    You can find the code here: https://github.com/davek44/Basset\n",
        "    \"\"\"\n",
        "\n",
        "    # Initializes the BassetDataset\n",
        "    def __init__(self, path='./data/', f5name='er.h5', split='train', transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            :param path: path to HDF5 file\n",
        "            :param f5name: HDF5 file name\n",
        "            :param split: split that we are interested to work with\n",
        "            :param transform (callable, optional): Optional transform to be applied on a sample\n",
        "        \"\"\"\n",
        "\n",
        "        self.split = split\n",
        "\n",
        "        split_dict = {'train': ['train_in', 'train_out'],\n",
        "                      'test': ['test_in', 'test_out'],\n",
        "                      'valid': ['valid_in', 'valid_out']}\n",
        "\n",
        "        assert self.split in split_dict, \"'split' argument can be only defined as 'train', 'valid' or 'test'\"\n",
        "\n",
        "        # Open hdf5 file where one-hoted data are stored\n",
        "        self.dataset = h5py.File(os.path.join(path, f5name.format(self.split)), 'r')\n",
        "\n",
        "        # Keeping track of the names of the target labels\n",
        "        self.target_labels = self.dataset['target_labels']\n",
        "\n",
        "        # Get the list of volumes\n",
        "        self.inputs = self.dataset[split_dict[split][0]]\n",
        "        self.outputs = self.dataset[split_dict[split][1]]\n",
        "\n",
        "        self.ids = list(range(len(self.inputs)))\n",
        "        if self.split == 'test':\n",
        "            self.id_vars = np.char.decode(self.dataset['test_headers'])\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        \"\"\"\n",
        "        Returns the sequence and the target at index i\n",
        "\n",
        "        Notes:\n",
        "        * The data is stored as float16, however, your model will expect float32.\n",
        "          Do the type conversion here!\n",
        "        * Pay attention to the output shape of the data.\n",
        "          Change it to match what the model is expecting\n",
        "          hint: https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html\n",
        "        * The target must also be converted to float32\n",
        "        \"\"\"\n",
        "\n",
        "        idx = self.ids[i]\n",
        "        # WRITE CODE HERE\n",
        "\n",
        "        seq = self.inputs[idx]\n",
        "        target = self.outputs[idx]\n",
        "\n",
        "        seq = np.transpose(seq, (1, 2, 0)).astype(np.float32)\n",
        "        target = np.float32(target)\n",
        "\n",
        "        seq = torch.from_numpy(seq)\n",
        "        target = torch.from_numpy(target)\n",
        "        # Sequence & Target\n",
        "        output = {'sequence': seq, \n",
        "                  'target': target}\n",
        "        return output\n",
        "\n",
        "    def __len__(self):\n",
        "        # WRITE CODE HERE\n",
        "        return len(self.inputs)\n",
        "\n",
        "    def get_seq_len(self):\n",
        "        \"\"\"\n",
        "        Answer to Q1 part 2\n",
        "        \"\"\"\n",
        "        # WRITE CODE HERE\n",
        "        return self.inputs[0].shape[-1]\n",
        "\n",
        "    def is_equivalent(self):\n",
        "        \"\"\"\n",
        "        Answer to Q1 part 3\n",
        "        \"\"\"\n",
        "        # WRITE CODE HERE\n",
        "        return True\n",
        "\n",
        "\n",
        "class Basset(nn.Module):\n",
        "    \"\"\"\n",
        "    Basset model\n",
        "    Architecture specifications can be found in the supplementary material\n",
        "    You will also need to use some Convolution Arithmetic\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Basset, self).__init__()\n",
        "\n",
        "        self.num_cell_types = 164\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1, 300, (19, 4), stride=(1, 1), padding=(9, 0))\n",
        "        self.conv2 = nn.Conv2d(300, 200, (11, 1), stride=(1, 1), padding=(5, 0))\n",
        "        self.conv3 = nn.Conv2d(200 , 200, (7, 1), stride=(1, 1), padding=(4, 0))\n",
        "\n",
        "        self.bn1 = nn.BatchNorm2d(300)\n",
        "        self.bn2 = nn.BatchNorm2d(200)\n",
        "        self.bn3 = nn.BatchNorm2d(200)\n",
        "        self.maxpool1 = nn.MaxPool2d((3, 1))\n",
        "        self.maxpool2 = nn.MaxPool2d((4, 1))\n",
        "        self.maxpool3 = nn.MaxPool2d((4, 1))\n",
        "\n",
        "        self.fc1 = nn.Linear(13*200, 1000)\n",
        "        self.bn4 = nn.BatchNorm1d(1000)\n",
        "\n",
        "        self.fc2 = nn.Linear(1000, 1000)\n",
        "        self.bn5 = nn.BatchNorm1d(1000)\n",
        "\n",
        "        self.fc3 = nn.Linear(1000, self.num_cell_types)\n",
        "        self.dropout = 0.3\n",
        "        self.drop = nn.Dropout(self.dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # WRITE CODE HERE\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.maxpool1(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.maxpool2(x)\n",
        "\n",
        "        x = self.conv3(x)\n",
        "        x = self.bn3(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.maxpool3(x)\n",
        "\n",
        "        x = x.view(-1, 13*200)\n",
        "\n",
        "        x = self.fc1(x)\n",
        "        x = self.bn4(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.drop(x)\n",
        "\n",
        "        x = self.fc2(x)\n",
        "        x = self.bn5(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.drop(x)\n",
        "\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "def compute_fpr_tpr(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Computes the False Positive Rate and True Positive Rate\n",
        "    Args:\n",
        "        :param y_true: groundtruth labels (np.array of ints)\n",
        "        :param y_pred: model decisions (np.array of ints)\n",
        "\n",
        "    :Return: dict with tpr, fpr (values are floats)\n",
        "    \"\"\"\n",
        "    output = {'fpr': 0., 'tpr': 0.}\n",
        "\n",
        "    # WRITE CODE HERE\n",
        "    \n",
        "    fp = np.sum((y_pred == 1) & (y_true == 0))\n",
        "    tp = np.sum((y_pred == 1) & (y_true == 1))\n",
        "\n",
        "    fn = np.sum((y_pred == 0) & (y_true == 1))\n",
        "    tn = np.sum((y_pred == 0) & (y_true == 0))\n",
        "\n",
        "    fpr = fp / (fp + tn)\n",
        "    tpr = tp / (tp + fn)\n",
        "\n",
        "    output = {'fpr': fpr, 'tpr': tpr}\n",
        "    return output\n",
        "\n",
        "\n",
        "def compute_fpr_tpr_dumb_model():\n",
        "    \"\"\"\n",
        "    Simulates a dumb model and computes the False Positive Rate and True Positive Rate\n",
        "\n",
        "    :Return: dict with tpr_list, fpr_list.\n",
        "             These lists contain the tpr and fpr for different thresholds\n",
        "             fpr and tpr values in the lists should be floats\n",
        "             Order the lists such that:\n",
        "                 output['fpr_list'][0] corresponds to k=0.\n",
        "                 output['fpr_list'][1] corresponds to k=0.05 \n",
        "                 ...\n",
        "            Do the same for output['tpr_list']\n",
        "             \n",
        "    \"\"\"\n",
        "    output = {'fpr_list': [], 'tpr_list': []}\n",
        "\n",
        "    # WRITE CODE HERE\n",
        "    target = np.random.randint(2, size= 1000)\n",
        "    preds = np.random.uniform(low = 0,high = 1,size = 1000)\n",
        "\n",
        "    thresholds = np.arange(0,1,0.05)\n",
        "    for k in thresholds:\n",
        "        y_pred = np.where(preds >= k, 1, 0)\n",
        "\n",
        "        fp = np.sum((y_pred == 1) & (target == 0))\n",
        "        tp = np.sum((y_pred == 1) & (target == 1))\n",
        "        fn = np.sum((y_pred == 0) & (target == 1))\n",
        "        tn = np.sum((y_pred == 0) & (target == 0))\n",
        "\n",
        "        output[\"fpr_list\"].append(fp / (fp + tn))\n",
        "        output[\"tpr_list\"].append(tp / (tp + fn))\n",
        "\n",
        "    return output\n",
        "\n",
        "\n",
        "def compute_fpr_tpr_smart_model():\n",
        "    \"\"\"\n",
        "    Simulates a smart model and computes the False Positive Rate and True Positive Rate\n",
        "\n",
        "    :Return: dict with tpr_list, fpr_list.\n",
        "             These lists contain the tpr and fpr for different thresholds\n",
        "             fpr and tpr values in the lists should be floats\n",
        "             Order the lists such that:\n",
        "                 output['fpr_list'][0] corresponds to k=0.\n",
        "                 output['fpr_list'][1] corresponds to k=0.05 \n",
        "                 ...\n",
        "            Do the same for output['tpr_list']\n",
        "    \"\"\"\n",
        "    output = {'fpr_list': [], 'tpr_list': []}\n",
        "\n",
        "    # WRITE CODE HERE\n",
        "\n",
        "    #simulate target\n",
        "    target = np.random.randint(2, size= 1000)\n",
        "\n",
        "    #simulate preds\n",
        "    inds_true = np.where(target==1)[0] \n",
        "    inds_false = np.where(target==0)[0]\n",
        "\n",
        "    preds_true = np.random.uniform(low = 0.4,high = 1, size=len(inds_true))\n",
        "    preds_false = np.random.uniform(low = 0,high = 0.6, size=len(inds_false))\n",
        "\n",
        "    preds = np.empty(shape = (1000,))\n",
        "    np.put(preds, inds_true, preds_true)\n",
        "    np.put(preds, inds_false, preds_false)    \n",
        "    \n",
        "    #setting thresholds\n",
        "    thresholds = np.arange(0,1,0.05)\n",
        "    for k in thresholds:\n",
        "        y_pred = np.where(preds >= k, 1, 0)\n",
        "\n",
        "        fp = np.sum((y_pred == 1) & (target == 0))\n",
        "        tp = np.sum((y_pred == 1) & (target == 1))\n",
        "        fn = np.sum((y_pred == 0) & (target == 1))\n",
        "        tn = np.sum((y_pred == 0) & (target == 0))\n",
        "\n",
        "        output[\"fpr_list\"].append(fp / (fp + tn))\n",
        "        output[\"tpr_list\"].append(tp / (tp + fn))\n",
        "\n",
        "    return output\n",
        "\n",
        "\n",
        "def compute_auc_both_models():\n",
        "    \"\"\"\n",
        "    Simulates a dumb model and a smart model and computes the AUC of both\n",
        "    :Return: dict with keys 'auc_dumb_model', 'auc_smart_model'.\n",
        "             These contain the AUC for both models\n",
        "             auc values in the lists should be floats\n",
        "    \"\"\"\n",
        "\n",
        "    output = {'auc_dumb_model': 0., 'auc_smart_model': 0.}\n",
        "\n",
        "    # WRITE CODE HERE\n",
        "\n",
        "    ####### dumb model\n",
        "\n",
        "    target_dumb = np.random.randint(2, size= 1000)\n",
        "    preds_dumb = np.random.uniform(low = 0,high = 1,size = 1000)\n",
        "\n",
        "    ####### smart model\n",
        "\n",
        "     #simulate target\n",
        "    target_smart = np.random.randint(2, size= 1000)\n",
        "\n",
        "    #simulate preds\n",
        "    inds_true = np.where(target_smart==1)[0] \n",
        "    inds_false = np.where(target_smart==0)[0]\n",
        "\n",
        "    preds_true = np.random.uniform(low = 0.4,high = 1, size=len(inds_true))\n",
        "    preds_false = np.random.uniform(low = 0,high = 0.6, size=len(inds_false))\n",
        "\n",
        "    preds_smart = np.empty(shape = (1000,))\n",
        "    np.put(preds_smart, inds_true, preds_true)\n",
        "    np.put(preds_smart, inds_false, preds_false)  \n",
        "\n",
        "    output[\"auc_dumb_model\"] = compute_auc(target_dumb, preds_dumb)[\"auc\"]\n",
        "    output[\"auc_smart_model\"] = compute_auc(target_smart, preds_smart)[\"auc\"]\n",
        "    print(output)\n",
        "\n",
        "    return output\n",
        "\n",
        "\n",
        "def compute_auc_untrained_model(model, dataloader, device):\n",
        "    \"\"\"\n",
        "    Computes the AUC of your input model\n",
        "    Args:\n",
        "        :param model: solution.Basset()\n",
        "        :param dataloader: torch.utils.data.DataLoader\n",
        "                           Where the dataset is solution.BassetDataset\n",
        "        :param device: torch.device\n",
        "    :Return: dict with key 'auc'.\n",
        "             This contains the AUC for the model\n",
        "             auc value should be float\n",
        "    Notes:\n",
        "    * Dont forget to re-apply your output activation!\n",
        "    * Make sure this function works with arbitrarily small dataset sizes!\n",
        "    * You should collect all the targets and model outputs and then compute AUC at the end\n",
        "      (compute time should not be as much of a consideration here)\n",
        "    \"\"\"\n",
        "    output = {'auc': 0.}\n",
        "\n",
        "    # WRITE CODE HERE\n",
        "    # model = Basset()\n",
        "    y_pred = torch.tensor([], device=device)\n",
        "    y_true = torch.tensor([], device=device)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "                batch_x = batch[\"sequence\"]\n",
        "                batch_y = batch[\"target\"]\n",
        "\n",
        "                batch_x = batch_x.to(device)\n",
        "                batch_y = batch_y.to(device)\n",
        "\n",
        "                preds = model(batch_x)\n",
        "                # print(pred.shape)\n",
        "\n",
        "                y_true = torch.cat((y_true, batch_y), 0)\n",
        "                y_pred = torch.cat((y_pred, preds), 0)\n",
        "\n",
        "    y_true = y_true.cpu().numpy()  \n",
        "    # _, y_pred = torch.max(y_pred, 1)\n",
        "    # y_pred = y_pred.cpu().numpy()\n",
        "    y_pred_prob = torch.sigmoid(y_pred).cpu().numpy()\n",
        "\n",
        "    output[\"auc\"] = compute_auc(y_true, y_pred_prob)[\"auc\"]\n",
        "    return output\n",
        "\n",
        "\n",
        "def compute_auc(y_true, y_model):\n",
        "    \"\"\"\n",
        "    Computes area under the ROC curve (using method described in main.ipynb)\n",
        "    Args:\n",
        "        :param y_true: groundtruth labels (np.array of ints [0 or 1])\n",
        "        :param y_model: model outputs (np.array of float32 in [0, 1])\n",
        "    :Return: dict with key 'auc'.\n",
        "             This contains the AUC for the model\n",
        "             auc value should be float\n",
        "    Note: if you set y_model as the output of solution.Basset, \n",
        "    you need to transform it before passing it here!\n",
        "    \"\"\"\n",
        "    output = {'auc': 0.}\n",
        "    #reference: https://medium.com/building-ibotta/understanding-roc-auc-part-2-2-a1e418a3afdb\n",
        "    # Total number of observations\n",
        "    # N = y_true.shape[0]\n",
        "    \n",
        "    # # Index vector\n",
        "    # I = np.arange(1, N + 1)\n",
        "    \n",
        "    # # Number of positive observations\n",
        "    # N_pos = np.sum(y_true)\n",
        "    \n",
        "    # # Number of negative observations\n",
        "    # N_neg = N - N_pos\n",
        "    \n",
        "    # # Sort true labels according to scores\n",
        "    # I = y_model.argsort()[::-1][:N]\n",
        "    # y_pred = y_true[I]\n",
        "    \n",
        "    # # Index vector\n",
        "    # I = np.arange(1, N + 1)\n",
        "    \n",
        "    # output[\"auc\"] = 1. + ((N_pos + 1.) / (2 * N_neg)) - (1. / (N_pos * N_neg)) * I.dot(y_pred)\n",
        "\n",
        "    fpr_tpr = {'fpr_list': np.array([]), 'tpr_list': np.array([])}\n",
        "    for thresh in np.arange(0, 1, 0.05):\n",
        "        y_pred_th = y_model > thresh\n",
        "        y_pred_th = y_pred_th.astype(int)\n",
        "        out = compute_fpr_tpr(y_true, y_pred_th)\n",
        "        fpr_tpr['fpr_list'] = np.append(fpr_tpr['fpr_list'], out['fpr'])\n",
        "        fpr_tpr['tpr_list'] = np.append(fpr_tpr['tpr_list'], out['tpr'])\n",
        "    print(fpr_tpr['fpr_list'])\n",
        "    print(fpr_tpr['tpr_list'])\n",
        "    dx = np.diff(fpr_tpr['fpr_list'])\n",
        "\n",
        "    left_riemann_sum = abs(np.sum(fpr_tpr['tpr_list'][:-1] * dx))\n",
        "    print(\"Left Riemann Sum:\",left_riemann_sum)\n",
        "\n",
        "    right_riemann_sum = abs(np.sum(fpr_tpr['tpr_list'][1:] * dx))\n",
        "    print(\"Right Riemann Sum:\",right_riemann_sum)\n",
        "\n",
        "    output[\"auc\"] = (left_riemann_sum + right_riemann_sum)/2\n",
        "\n",
        "    return output\n",
        "\n",
        "\n",
        "def get_critereon():\n",
        "    \"\"\"\n",
        "    Picks the appropriate loss function for our task\n",
        "    criterion should be subclass of torch.nn\n",
        "    \"\"\"\n",
        "\n",
        "    # WRITE CODE HERE\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    return criterion\n",
        "\n",
        "def compute_auc_trained_model(y_model, y_true):\n",
        "    # print(\"compute auc\")\n",
        "    # print(type(y_model))\n",
        "    # print(type(y_true))\n",
        "    y_model = y_model.cpu().detach().numpy()\n",
        "    y_true = y_true.cpu().detach().numpy()\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    fpr_tpr = {'fpr_list': np.array([]), 'tpr_list': np.array([])}\n",
        "    for thresh in np.arange(0, 1, 0.05):\n",
        "        y_pred_th = y_model > thresh\n",
        "        y_pred_th = y_pred_th.astype(int)\n",
        "        out = compute_fpr_tpr(y_true, y_pred_th)\n",
        "        fpr_tpr['fpr_list'] = np.append(fpr_tpr['fpr_list'], out['fpr'])\n",
        "        fpr_tpr['tpr_list'] = np.append(fpr_tpr['tpr_list'], out['tpr'])\n",
        "    # print(fpr_tpr['fpr_list'])\n",
        "    # print(fpr_tpr['tpr_list'])\n",
        "    dx = np.diff(fpr_tpr['fpr_list'])\n",
        "\n",
        "    left_riemann_sum = abs(np.sum(fpr_tpr['tpr_list'][:-1] * dx))\n",
        "    # print(\"Left Riemann Sum:\",left_riemann_sum)\n",
        "\n",
        "    right_riemann_sum = abs(np.sum(fpr_tpr['tpr_list'][1:] * dx))\n",
        "    # print(\"Right Riemann Sum:\",right_riemann_sum)\n",
        "    auc = (left_riemann_sum + right_riemann_sum)/2\n",
        "    return auc\n",
        "\n",
        "def evaluate_model(model, dataset_loader, optimizer, criterion, device, type = \"loss\"):\n",
        "    LOSSES = 0\n",
        "    COUNTER = 0\n",
        "    model.eval()\n",
        "    for batch in dataset_loader:\n",
        "        # optimizer.zero_grad()\n",
        "\n",
        "        batch_x = batch[\"sequence\"]\n",
        "        batch_y = batch[\"target\"]\n",
        "\n",
        "        batch_x = batch_x.to(device)\n",
        "        batch_y = batch_y.to(device)\n",
        "        \n",
        "        loss = criterion(model(batch_x), batch_y)\n",
        "\n",
        "        if(type == \"loss\"):\n",
        "            n = batch_y.size(0)\n",
        "            LOSSES += loss.sum().cpu().data.numpy() * n\n",
        "            COUNTER += n\n",
        "        else:\n",
        "            n = batch_y.size(0)\n",
        "            LOSSES += loss.sum() * n\n",
        "            COUNTER += n\n",
        "\n",
        "    return LOSSES / float(COUNTER)\n",
        "    \n",
        "# def train_loop(model, train_dataloader, device, optimizer, criterion):\n",
        "#     \"\"\"\n",
        "#     One Iteration across the training set\n",
        "#     Args:\n",
        "#         :param model: solution.Basset()\n",
        "#         :param train_dataloader: torch.utils.data.DataLoader\n",
        "#                                  Where the dataset is solution.BassetDataset\n",
        "#         :param device: torch.device\n",
        "#         :param optimizer: torch.optim\n",
        "#         :param critereon: torch.nn (output of get_critereon)\n",
        "#     :Return: total_score, total_loss.\n",
        "#              float of model score (AUC) and float of model loss for the entire loop (epoch)\n",
        "#              (if you want to display losses and/or scores within the loop, \n",
        "#              you may print them to screen)\n",
        "#     Make sure your loop works with arbitrarily small dataset sizes!\n",
        "#     Note: you don’t need to compute the score after each training iteration.\n",
        "#     If you do this, your training loop will be really slow!\n",
        "#     You should instead compute it every 50 or so iterations and aggregate ...\n",
        "#     \"\"\"\n",
        "\n",
        "#     output = {'total_score': 0.,\n",
        "#               'total_loss': 0.}\n",
        "\n",
        "#     # WRITE CODE HERE\n",
        "\n",
        "#     # load the data\n",
        "#     # mnist_train = datasets.MNIST('data', train=True, download=True)\n",
        "#     # mnist_train = list(mnist_train)[:2000]\n",
        "#     # img_to_tensor = transforms.ToTensor()\n",
        "\n",
        "#     # create a new model, initialize random parameters\n",
        "#     model.train()\n",
        "    \n",
        "#     LOSSES = 0\n",
        "#     COUNTER = 0\n",
        "#     ITERATIONS = 0\n",
        "#     store_every = 50\n",
        "#     learning_curve_loss_train = list()\n",
        "#     learning_curve_auc_train = list()\n",
        "#     learning_curve_auc_batch_train = list()\n",
        "\n",
        "#     # training\n",
        "#     for batch in train_dataloader:\n",
        "#         optimizer.zero_grad()\n",
        "\n",
        "#         batch_x = batch[\"sequence\"]\n",
        "#         batch_y = batch[\"target\"]\n",
        "\n",
        "#         batch_x = batch_x.to(device)\n",
        "#         batch_y = batch_y.to(device)\n",
        "\n",
        "#         model = model.to(device)\n",
        "            \n",
        "#         loss = criterion(model(batch_x), batch_y)\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "        \n",
        "#         n = batch_y.size(0)\n",
        "#         # print(f\"loss sum data type {type(loss.sum()}\")\n",
        "#         # print()\n",
        "#         # print(type(loss.sum().data))\n",
        "#         LOSSES += loss.sum().cpu().data.numpy() * n\n",
        "#         COUNTER += n\n",
        "#         ITERATIONS += 1\n",
        "#         if ITERATIONS%(store_every/5) == 0:\n",
        "#             avg_loss = LOSSES / float(COUNTER)\n",
        "#             LOSSES = 0\n",
        "#             COUNTER = 0\n",
        "#             print(\" Iteration {}: TRAIN {}\".format(\n",
        "#                 ITERATIONS, avg_loss))\n",
        "#             output['total_loss'] = avg_loss\n",
        "\n",
        "    \n",
        "#         if ITERATIONS%(store_every) == 0:     \n",
        "#             train_loss = evaluate_model(model, train_dataloader, optimizer, criterion, device, type = \"loss\")\n",
        "#             learning_curve_loss_train.append(train_loss)\n",
        "\n",
        "#             train_batch_auc = compute_auc_trained_model(model(batch_x), batch_y)\n",
        "#             learning_curve_auc_batch_train.append(train_batch_auc)\n",
        "\n",
        "#             train_auc = evaluate_model(model, train_dataloader, optimizer, compute_auc_trained_model, device, type = \"auc\")\n",
        "#             learning_curve_auc_train.append(train_auc)\n",
        "                   \n",
        "#             print(\" [LOSS] TRAIN {}\".format(\n",
        "#                 train_loss))\n",
        "#             print(\" [AUC] TRAIN {}\".format(\n",
        "#                 train_auc))\n",
        "#             print(\" [AUC] TRAIN BATCH {}\".format(\n",
        "#                 train_batch_auc))\n",
        "            \n",
        "\n",
        "#     output['total_score'] = sum(learning_curve_auc_batch_train) / len(learning_curve_auc_batch_train)\n",
        "#     # print(f\"TOTAL list auc length: {len(learning_curve_auc_train)}\")\n",
        "#     print(\"AUC after one complete epoch\")\n",
        "#     print(output['total_score'])\n",
        "#     return output['total_score'], output['total_loss']\n",
        "\n",
        "def train_loop(model, train_dataloader, device, optimizer, criterion):\n",
        "        output = {'total_score': 0.,\n",
        "              'total_loss': 0.}\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        num_train_correct  = 0\n",
        "        num_train_examples = 0\n",
        "\n",
        "        for i, batch in enumerate(tqdm(train_dataloader)):\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            batch_x = batch[\"sequence\"]\n",
        "            batch_y = batch[\"target\"]\n",
        "\n",
        "            batch_x = batch_x.to(device)\n",
        "            batch_y = batch_y.to(device)\n",
        "\n",
        "            model = model.to(device)\n",
        "            yhat = model(batch_x)\n",
        "            loss = criterion(yhat, batch_y)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.data.item() * batch_x.size(0)\n",
        "            # num_train_correct  += (torch.max(yhat, 1)[1] == batch_y).sum().item()\n",
        "            num_train_examples += batch_x.shape[0]\n",
        "            \n",
        "\n",
        "        # train_acc   = num_train_correct / num_train_examples\n",
        "        train_loss  = train_loss / len(train_dataloader.dataset)\n",
        "        print(\"[TOTAL DL LOSS] TRAIN {}\".format(\n",
        "            train_loss\n",
        "        ))\n",
        "        # output = {'total_score': train_acc,\n",
        "        #       'total_loss': train_loss}\n",
        "        return train_loss\n",
        "\n",
        "\n",
        "\n",
        "def valid_loop(model, valid_dataloader, device, optimizer, criterion):\n",
        "    \"\"\"\n",
        "    One Iteration across the validation set\n",
        "    Args:\n",
        "        :param model: solution.Basset()\n",
        "        :param valid_dataloader: torch.utils.data.DataLoader\n",
        "                                 Where the dataset is solution.BassetDataset\n",
        "        :param device: torch.device\n",
        "        :param optimizer: torch.optim\n",
        "        :param critereon: torch.nn (output of get_critereon)\n",
        "    :Return: total_score, total_loss.\n",
        "             float of model score (AUC) and float of model loss for the entire loop (epoch)\n",
        "             (if you want to display losses and/or scores within the loop, \n",
        "             you may print them to screen)\n",
        "    Make sure your loop works with arbitrarily small dataset sizes!\n",
        "    \n",
        "    Note: if it is taking very long to run, \n",
        "    you may do simplifications like with the train_loop.\n",
        "    \"\"\"\n",
        "\n",
        "    output = {'total_score': 0.,\n",
        "              'total_loss': 0.}\n",
        "\n",
        "    # WRITE CODE HERE\n",
        "\n",
        "    val_loss = evaluate_model(model, valid_dataloader, optimizer, criterion, device, type = \"loss\")\n",
        "    val_auc = evaluate_model(model, valid_dataloader, optimizer, compute_auc_trained_model, device, type = \"auc\")\n",
        "    print(\" [LOSS] VALID {}\".format(\n",
        "                val_loss))\n",
        "    print(\" [AUC] VALID {}\".format(\n",
        "                val_auc))\n",
        "\n",
        "    output['total_score'] = val_auc\n",
        "    output['total_loss'] = val_loss         \n",
        "    return output['total_score'], output['total_loss']\n"
      ],
      "metadata": {
        "id": "tdGgag6xLAlr"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "8EFHMkC6RGG3"
      },
      "outputs": [],
      "source": [
        "model = Basset().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_ckp(checkpoint_fpath, model, optimizer, valid_loss_min, epoch):\n",
        "    \"\"\"\n",
        "    checkpoint_path: path to save checkpoint\n",
        "    model: model that we want to load checkpoint parameters into       \n",
        "    optimizer: optimizer we defined in previous training\n",
        "    \"\"\"\n",
        "    # load check point\n",
        "    model = torch.load(checkpoint_fpath)\n",
        "    # initialize state_dict from checkpoint to model\n",
        "    # model.load_state_dict(checkpoint['state_dict'])\n",
        "    # initialize optimizer from checkpoint to optimizer\n",
        "    # optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "    # initialize valid_loss_min from checkpoint to valid_loss_min\n",
        "    # valid_loss_min = checkpoint['valid_loss_min']\n",
        "    # return model, optimizer, epoch value, min validation loss \n",
        "    return model, optimizer, epoch, valid_loss_min"
      ],
      "metadata": {
        "id": "PcXoGqT7eRkg"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_fpath = \"/content/model_params_epoch_2.pt\"\n",
        "optimizer = optim.Adam(list(model.parameters()), lr=learning_rate, betas=(0.9, 0.999))\n",
        "epoch = 2\n",
        "valid_loss_min = 0.08184701588758066\n",
        "\n",
        "model, optimizer, start_epoch, valid_loss_min = load_ckp(checkpoint_fpath, model, optimizer, valid_loss_min, epoch)"
      ],
      "metadata": {
        "id": "HXzQtYeAeUKf"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpHfTqxhYER_"
      },
      "source": [
        "# **Question 3 (Area Under the Curve)** \n",
        "(25 points). Each DNA sequence is either exposed (we'll call this the positive case) or not (we'll call this the negative case). The output of our model should be used to return a binary decision about the sequence.\n",
        "\n",
        "For a given case, we say that our model made a positive prediction whenever its output value is above some threshold $k$, and a negative prediction otherwise.\n",
        "\n",
        "Define the *True Positive Rate* (TPR) as the number of correctly prediced positive cases divided by the number of positive cases. Define the *False Positive Rate* (FPR) as the  number of cases that were incorrectly predicted as positive divided by the number of negative cases.\n",
        "\n",
        "1. Complete the function `compute_fpr_tpr` in `solution.py`. This code will compute the TPR and FPR given your models decisions and the true targets.\n",
        "\n",
        "2. Your FPR and TPR change as a function of $k$. Specifically, we can plot the FPR on the x-axis and the TPR on the y-axis for different values of $k$. The shape of the resulting curve (ROC curve) tells us something about our classifiers performance. We will explore via simulation what this plot looks like when our model is just making random guesses. In `solution.py`, fill in the function `compute_fpr_tpr_dumb_model`. This function will generate 1000 binary random variables to use as targets and 1000 uniform random variables between 0 and 1 as our model predictions. It will then compute the fpr and tpr for $k\\in \\{0, 0.05,..., 0.95, 1\\}$ You should plot what the ROC curves look like for your own knowledge."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_ewjBEFw-Gr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59addb4b-79e7-4540-cbff-b81c0f6afafd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'fpr_list': [1.0,\n",
              "  0.9469387755102041,\n",
              "  0.8918367346938776,\n",
              "  0.8387755102040816,\n",
              "  0.773469387755102,\n",
              "  0.7061224489795919,\n",
              "  0.6693877551020408,\n",
              "  0.6306122448979592,\n",
              "  0.5857142857142857,\n",
              "  0.5428571428571428,\n",
              "  0.49183673469387756,\n",
              "  0.45102040816326533,\n",
              "  0.39591836734693875,\n",
              "  0.35714285714285715,\n",
              "  0.29183673469387755,\n",
              "  0.23265306122448978,\n",
              "  0.19591836734693877,\n",
              "  0.16326530612244897,\n",
              "  0.09387755102040816,\n",
              "  0.04897959183673469],\n",
              " 'tpr_list': [1.0,\n",
              "  0.9490196078431372,\n",
              "  0.9156862745098039,\n",
              "  0.8568627450980392,\n",
              "  0.807843137254902,\n",
              "  0.7549019607843137,\n",
              "  0.7058823529411765,\n",
              "  0.6607843137254902,\n",
              "  0.6098039215686275,\n",
              "  0.5607843137254902,\n",
              "  0.5078431372549019,\n",
              "  0.4627450980392157,\n",
              "  0.41568627450980394,\n",
              "  0.35490196078431374,\n",
              "  0.2980392156862745,\n",
              "  0.2647058823529412,\n",
              "  0.21372549019607842,\n",
              "  0.1568627450980392,\n",
              "  0.10196078431372549,\n",
              "  0.045098039215686274]}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "compute_fpr_tpr_dumb_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cWBplcrw8wl"
      },
      "source": [
        "3. We will now simulate a better model. In `solution.py`, fill in the function `compute_fpr_tpr_smart_model`. This will simulate 1000 targets the same way as before. However, this will simulate model outputs as uniform random variables between 0.4 and 1 for the positive cases. For the negative cases, simulate uniform random variables between 0 and 0.6. Compute the tpr and fpr varying $k$ like before. You should also look at the ROC curve."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Vdr40asxBUu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd1f8a3a-b4d2-400b-a020-6e3775bb3dee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'fpr_list': [1.0,\n",
              "  0.8928571428571429,\n",
              "  0.8298319327731093,\n",
              "  0.7521008403361344,\n",
              "  0.6596638655462185,\n",
              "  0.5714285714285714,\n",
              "  0.5021008403361344,\n",
              "  0.4264705882352941,\n",
              "  0.3550420168067227,\n",
              "  0.2710084033613445,\n",
              "  0.16806722689075632,\n",
              "  0.09873949579831932,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0],\n",
              " 'tpr_list': [1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  0.9122137404580153,\n",
              "  0.8263358778625954,\n",
              "  0.7690839694656488,\n",
              "  0.6812977099236641,\n",
              "  0.601145038167939,\n",
              "  0.5019083969465649,\n",
              "  0.41030534351145037,\n",
              "  0.32633587786259544,\n",
              "  0.25,\n",
              "  0.1736641221374046,\n",
              "  0.06679389312977099]}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "compute_fpr_tpr_smart_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-rqX9_UxBkK"
      },
      "source": [
        "4. The Area Under the ROC Curve (AUC) summarizes the ROC plot as a single number. It is literally computed as the area under the the ROC curve (take the average of the left and right Reimann sums). Complete the function `utils.compute_auc` and use it in the function `compute_auc_both_models` to compute the AUC of the ROC curves you made in parts 2 and 3."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "compute_auc_both_models()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLj5Ovbk4Gro",
        "outputId": "21e1eae3-4aed-4511-9551-a182b32582f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.         0.96267191 0.90373281 0.85068762 0.79764244 0.75049116\n",
            " 0.6935167  0.64243615 0.5913556  0.54420432 0.49705305 0.46168959\n",
            " 0.39489194 0.34381139 0.29076621 0.25147348 0.2043222  0.12770138\n",
            " 0.09233792 0.05304519]\n",
            "[1.         0.94501018 0.87780041 0.83095723 0.77800407 0.72505092\n",
            " 0.6802444  0.63543788 0.56822811 0.50101833 0.45621181 0.4114053\n",
            " 0.33808554 0.30142566 0.24032587 0.21588595 0.18126273 0.12627291\n",
            " 0.09164969 0.0407332 ]\n",
            "Left Riemann Sum: 0.49773326557804726\n",
            "Right Riemann Sum: 0.44874539350749637\n",
            "[1.         0.92121212 0.81212121 0.73535354 0.65656566 0.58989899\n",
            " 0.50707071 0.44444444 0.33939394 0.25656566 0.16565657 0.08484848\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.        ]\n",
            "[1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         0.91485149 0.84752475 0.76237624\n",
            " 0.66732673 0.58217822 0.47920792 0.37227723 0.31089109 0.23564356\n",
            " 0.17029703 0.0950495 ]\n",
            "Left Riemann Sum: 0.9597759775977599\n",
            "Right Riemann Sum: 0.9316571657165718\n",
            "{'auc_dumb_model': 0.4732393295427718, 'auc_smart_model': 0.9457165716571658}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'auc_dumb_model': 0.4732393295427718, 'auc_smart_model': 0.9457165716571658}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUDMl_NaxDjV"
      },
      "source": [
        "5. Complete the function `compute_auc_untrained_model`, which will compute the AUC of your untrained model. Use the first 100 batches of the test set.\n",
        "\n",
        "    Note: since we are doing multi-task prediction, your model outputs and targets will have shape (Batch size, Num targets). Flatten these matrices so that they are two vectors, each of size Batch size * Num targets.\n",
        "    Then, procede with AUC as if you were in the usual single task case..."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZ3cIgaEeLyX",
        "outputId": "40bc95eb-29d9-4cba-a663-fc4e3dff94c5"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Basset(\n",
              "  (conv1): Conv2d(1, 300, kernel_size=(19, 4), stride=(1, 1), padding=(9, 0))\n",
              "  (conv2): Conv2d(300, 200, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0))\n",
              "  (conv3): Conv2d(200, 200, kernel_size=(7, 1), stride=(1, 1), padding=(4, 0))\n",
              "  (bn1): BatchNorm2d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (bn2): BatchNorm2d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (bn3): BatchNorm2d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (maxpool1): MaxPool2d(kernel_size=(3, 1), stride=(3, 1), padding=0, dilation=1, ceil_mode=False)\n",
              "  (maxpool2): MaxPool2d(kernel_size=(4, 1), stride=(4, 1), padding=0, dilation=1, ceil_mode=False)\n",
              "  (maxpool3): MaxPool2d(kernel_size=(4, 1), stride=(4, 1), padding=0, dilation=1, ceil_mode=False)\n",
              "  (fc1): Linear(in_features=2600, out_features=1000, bias=True)\n",
              "  (bn4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (fc2): Linear(in_features=1000, out_features=1000, bias=True)\n",
              "  (bn5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (fc3): Linear(in_features=1000, out_features=164, bias=True)\n",
              "  (drop): Dropout(p=0.3, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "-yJn7gvzxEQT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b77cf06-9551-4d74-acd6-9e5046b53949"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.00000000e+00 1.26894690e-01 4.43028720e-02 2.09271644e-02\n",
            " 1.14794985e-02 6.81801595e-03 4.41095294e-03 3.06371618e-03\n",
            " 2.24782440e-03 1.69452446e-03 1.30705830e-03 1.00871369e-03\n",
            " 8.00705544e-04 6.41293375e-04 5.09390002e-04 3.92238979e-04\n",
            " 2.83418696e-04 1.91346670e-04 1.20969278e-04 5.92697395e-05]\n",
            "[1.         0.63772061 0.43830978 0.33931995 0.27746839 0.2337475\n",
            " 0.20439525 0.18366797 0.16584858 0.15098265 0.13690632 0.12360442\n",
            " 0.11118324 0.09958583 0.0884212  0.07699462 0.0647101  0.05147274\n",
            " 0.03701299 0.01978582]\n",
            "Left Riemann Sum: 0.9417869597207522\n",
            "Right Riemann Sum: 0.6057644368362777\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'auc': 0.7737756982785149}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "compute_auc_untrained_model(model, basset_dataloader_test, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXNicb2xL6_k"
      },
      "source": [
        "# **Question 4 (Training the Network)**\n",
        "(20 points) We will now write the training loop for Basset.\n",
        "\n",
        "1. Notice that for each input, we have one target per experiment, and each target is binary. Write the function `get_critereon`, which will pick the appropriate `loss` function. \n",
        "\n",
        "  Hint: you may consult the [relevant PyTorch documentation](https://pytorch.org/docs/stable/nn.html#loss-functions)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "fiOOMTfRaz60"
      },
      "outputs": [],
      "source": [
        "criterion = get_critereon()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9y8MvhYcaZ4X"
      },
      "source": [
        "2. Finish the training loop by filling in the missing code for the `train_loop`  pass and `valid_loop` functions in `solution.py.`\n",
        "\n",
        "    Both loops must return the loss and AUC (computed the same way as the previous question). They must be returned by each function (see the docstring for more details)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "KE_ODCimT5n8"
      },
      "outputs": [],
      "source": [
        "# optimizer = optim.Adam(list(model.parameters()), lr=learning_rate, betas=(0.9, 0.999))\n",
        "\n",
        "# valid_score_best = 0\n",
        "# patience = 2\n",
        "# num_epochs = 5  # you don't need to train this for that long!\n",
        "\n",
        "# for e in tqdm(range(num_epochs)):\n",
        "#     train_loss = train_loop(model, basset_dataloader_train, device, optimizer, criterion)\n",
        "#     train_loss = evaluate_model(model, basset_dataloader_train, optimizer, criterion, device, type = \"loss\")\n",
        "\n",
        "#     train_auc = evaluate_model(model, basset_dataloader_train, optimizer, compute_auc_trained_model, device, type = \"auc\")\n",
        "                   \n",
        "#     print(\" [LOSS] TRAIN SINGLE EPOCH{}\".format(\n",
        "#                 train_loss))\n",
        "            \n",
        "#     print(\" [AUC] TRAIN SINGLE EPOCH {}\".format(\n",
        "#                 train_auc))\n",
        "    \n",
        "#     valid_score, valid_loss = valid_loop(model, basset_dataloader_valid, device, optimizer, criterion)\n",
        "\n",
        "#     print('epoch {}: loss={:.3f} score={:.3f}'.format(e,\n",
        "#                                                       valid_loss,\n",
        "#                                                       valid_score))\n",
        "\n",
        "#     if valid_score > valid_score_best:\n",
        "#         print('Best score: {}. Saving model...'.format(valid_score))\n",
        "#         torch.save(model, 'model_params.pt')\n",
        "#         valid_score_best = valid_score\n",
        "#     else:\n",
        "#         patience -= 1\n",
        "#         print('Score did not improve! {} <= {}. Patience left: {}'.format(valid_score,\n",
        "#                                                                           valid_score_best,\n",
        "#                                                                           patience))\n",
        "#     if patience == 0:\n",
        "#         print('patience reduced to 0. Training Finished.')\n",
        "#         break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3WqwIe_2f3j"
      },
      "source": [
        "# **Question 5 (Interpreting the Model)**\n",
        "\n",
        "(30 points) In real-world applications of deep learning, it is *crucial* that we verify that our models are learning what we expect them to learn. In this exercise, we will replicate a part of figure 3b from [Basset](https://pubmed.ncbi.nlm.nih.gov/27197224/).\n",
        "\n",
        "In genetics, there exists well known DNA *motifs*: short sequences which appear throughtout our DNA, and whose function are well documented. We expect that the filters of the first convolution layer should learn to identify some of these motifs in order to solve this task.\n",
        "\n",
        "**Please submit the answers to this exercise on a single paged PDF!**\n",
        "\n",
        "1. First, we need to ensure that our model has learned something. Plot the ROC curve and compute the AUC of your model after training. Compare the ROC curves and the AUC before and after training with your simulated models. What do you notice?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n"
      ],
      "metadata": {
        "id": "wHwf8aB3hDWg"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_auc(y_true, y_model):\n",
        "\n",
        "    output = {'auc': 0.}\n",
        "\n",
        "    fpr_tpr = {'fpr_list': np.array([]), 'tpr_list': np.array([])}\n",
        "    for thresh in np.arange(0, 1, 0.05):\n",
        "        y_pred_th = y_model > thresh\n",
        "        y_pred_th = y_pred_th.astype(int)\n",
        "        out = compute_fpr_tpr(y_true, y_pred_th)\n",
        "        fpr_tpr['fpr_list'] = np.append(fpr_tpr['fpr_list'], out['fpr'])\n",
        "        fpr_tpr['tpr_list'] = np.append(fpr_tpr['tpr_list'], out['tpr'])\n",
        "    print(fpr_tpr['fpr_list'])\n",
        "    print(fpr_tpr['tpr_list'])\n",
        "    dx = np.diff(fpr_tpr['fpr_list'])\n",
        "\n",
        "    left_riemann_sum = abs(np.sum(fpr_tpr['tpr_list'][:-1] * dx))\n",
        "    print(\"Left Riemann Sum:\",left_riemann_sum)\n",
        "\n",
        "    right_riemann_sum = abs(np.sum(fpr_tpr['tpr_list'][1:] * dx))\n",
        "    print(\"Right Riemann Sum:\",right_riemann_sum)\n",
        "\n",
        "    output[\"auc\"] = (left_riemann_sum + right_riemann_sum)/2\n",
        "\n",
        "    return fpr_tpr['fpr_list'],fpr_tpr['tpr_list'], output[\"auc\"]"
      ],
      "metadata": {
        "id": "K8eYJ5m-m5iu"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_model_perf(model, untrained_model, dataloader, device):\n",
        "\n",
        "    # WRITE CODE HERE\n",
        "    # model = Basset()\n",
        "\n",
        "    \"\"\"\n",
        "    trained model eval\n",
        "    \"\"\"\n",
        "    y_pred = torch.tensor([], device=device)\n",
        "    y_true = torch.tensor([], device=device)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "                batch_x = batch[\"sequence\"]\n",
        "                batch_y = batch[\"target\"]\n",
        "\n",
        "                batch_x = batch_x.to(device)\n",
        "                batch_y = batch_y.to(device)\n",
        "\n",
        "                preds = model(batch_x)\n",
        "                # print(pred.shape)\n",
        "\n",
        "                y_true = torch.cat((y_true, batch_y), 0)\n",
        "                y_pred = torch.cat((y_pred, preds), 0)\n",
        "\n",
        "    y_true = y_true.cpu().numpy()  \n",
        "    (unique, counts) = np.unique(y_true, return_counts=True)\n",
        "    print(\"unique counts\")\n",
        "    print(unique)\n",
        "\n",
        "    print(y_true.shape)\n",
        "\n",
        "    # _, y_pred = torch.max(y_pred, 1)\n",
        "    # y_pred = y_pred.cpu().numpy()\n",
        "    y_pred_prob = torch.sigmoid(y_pred).cpu().numpy()\n",
        "\n",
        "    print(y_pred_prob.shape)\n",
        "\n",
        "    # fpr, tpr, threshold = metrics.roc_curve(y_true, y_pred_prob)\n",
        "    # roc_auc = metrics.auc(fpr, tpr)\n",
        "    # print(roc_auc)\n",
        "\n",
        "    \"\"\"\n",
        "    untrained model eval\n",
        "    \"\"\"\n",
        "\n",
        "    y_pred_un = torch.tensor([], device=device)\n",
        "    y_true_un = torch.tensor([], device=device)\n",
        "    untrained_model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "                batch_x = batch[\"sequence\"]\n",
        "                batch_y = batch[\"target\"]\n",
        "\n",
        "                batch_x = batch_x.to(device)\n",
        "                batch_y = batch_y.to(device)\n",
        "\n",
        "                preds_un = untrained_model(batch_x)\n",
        "                # print(pred.shape)\n",
        "\n",
        "                y_true_un = torch.cat((y_true_un, batch_y), 0)\n",
        "                y_pred_un = torch.cat((y_pred_un, preds_un), 0)\n",
        "\n",
        "    y_true_un = y_true_un.cpu().numpy()  \n",
        "    y_pred_prob_un = torch.sigmoid(y_pred_un).cpu().numpy()\n",
        "\n",
        "    #trained model metrics\n",
        "    fpr, tpr, auc = compute_auc(y_true_un, y_pred_prob)\n",
        "    #untrained model metrics\n",
        "    fpr_un, tpr_un, auc_un = compute_auc(y_true_un, y_pred_prob_un)\n",
        "    #plot the roc curve\n",
        "    plt.title('Receiver Operating Characteristic')\n",
        "    plt.plot(fpr, tpr, 'b', color='orange', label = 'AUC Trained Model= %0.2f' % auc)\n",
        "    plt.plot(fpr_un, tpr_un, 'b', label = 'AUC Untrained Model= %0.2f' % auc_un)\n",
        "    plt.legend(loc = 'lower right')\n",
        "    plt.plot([0, 1], [0, 1],'r--')\n",
        "    plt.xlim([0, 1])\n",
        "    plt.ylim([0, 1])\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "UM8_Ks5wfzlA"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plot models' roc curve\n",
        "plot_model_perf(model, untrained_model, basset_dataloader_test, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 741
        },
        "id": "fGxOU3o-fMIL",
        "outputId": "a30a1076-ef52-4976-f632-9b9c7431e12e"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unique counts\n",
            "[0. 1.]\n",
            "(71872, 164)\n",
            "(71872, 164)\n",
            "[1.00000000e+00 1.26894690e-01 4.43028720e-02 2.09271644e-02\n",
            " 1.14794985e-02 6.81801595e-03 4.41095294e-03 3.06371618e-03\n",
            " 2.24782440e-03 1.69452446e-03 1.30705830e-03 1.00871369e-03\n",
            " 8.00705544e-04 6.41293375e-04 5.09390002e-04 3.92238979e-04\n",
            " 2.83418696e-04 1.91346670e-04 1.20969278e-04 5.92697395e-05]\n",
            "[1.         0.63772061 0.43830978 0.33931995 0.27746839 0.2337475\n",
            " 0.20439525 0.18366797 0.16584858 0.15098265 0.13690632 0.12360442\n",
            " 0.11118324 0.09958583 0.0884212  0.07699462 0.0647101  0.05147274\n",
            " 0.03701299 0.01978582]\n",
            "Left Riemann Sum: 0.9417869597207522\n",
            "Right Riemann Sum: 0.6057644368362777\n",
            "[1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         0.54398947 0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.        ]\n",
            "[1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         0.56192938 0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.        ]\n",
            "Left Riemann Sum: 0.7616941966528257\n",
            "Right Riemann Sum: 0.2562457150161657\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiSdK0sue0up"
      },
      "source": [
        "2. We represent motifs as position weight matrices (PWMs). This is a matrix of size $4$ $\\times$ the motif length, where the $(i,j)$th entry is a count of how often base-pair $i$ occurs at position $j$. Open the PWM for the CTCF motif, which can be found in `MA0139.1.jaspar`. Normalize this matrix so that each column sums to $1$."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install biopython"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0beMokGNfav6",
        "outputId": "00a8dfd8-9810-4780-be41-92df797ae8b5"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting biopython\n",
            "  Downloading biopython-1.79-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 4.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from biopython) (1.21.5)\n",
            "Installing collected packages: biopython\n",
            "Successfully installed biopython-1.79\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from Bio import motifs\n",
        "from Bio.Seq import Seq"
      ],
      "metadata": {
        "id": "LCj14O-seb5n"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/MA0139.1.jaspar\") as f:\n",
        "  for m in motifs.parse(f, \"jaspar\"):\n",
        "    counts = m.counts\n",
        "    m.weblogo(\"CTCF.pdf\", format = \"pdf\", show_ends = False, show_fineprint = True, show_yaxis = False, show_errorbars = False)"
      ],
      "metadata": {
        "id": "Owqt82NbfjDR"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pwm_ctcf = counts.normalize()"
      ],
      "metadata": {
        "id": "vKNOm93ThUen"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(pwm_ctcf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zS6HvaPfhqRB",
        "outputId": "876c965e-5937-4120-d138-368dfaff585f"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        0      1      2      3      4      5      6      7      8      9     10     11     12     13     14     15     16     17     18\n",
            "A:   0.10   0.18   0.31   0.06   0.01   0.81   0.04   0.12   0.93   0.01   0.37   0.06   0.01   0.06   0.11   0.41   0.09   0.13   0.44\n",
            "C:   0.32   0.16   0.05   0.88   0.99   0.01   0.58   0.47   0.01   0.00   0.00   0.01   0.00   0.01   0.81   0.01   0.53   0.35   0.20\n",
            "G:   0.08   0.45   0.49   0.02   0.00   0.07   0.37   0.05   0.04   0.99   0.62   0.55   0.98   0.85   0.01   0.56   0.34   0.08   0.29\n",
            "T:   0.50   0.20   0.15   0.04   0.00   0.10   0.01   0.36   0.02   0.00   0.01   0.37   0.01   0.08   0.07   0.02   0.04   0.44   0.06\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1x6qoXteLaf"
      },
      "source": [
        "3. In the methods section of the [paper](https://pubmed.ncbi.nlm.nih.gov/27197224/) (page 998), the authors describe how they converted each of the $300$ filters into normalized PWMs. First, for each filter, they determined the maximum activated value across the *dataset* (you may use a subset of the test set here). Compute these values."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(m)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84pOIAzxm7Ih",
        "outputId": "3f4a8729-ade0-4c2d-c266-e17c7ca48d35"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF name\tCTCF\n",
            "Matrix ID\tMA0139.1\n",
            "Matrix:\n",
            "        0      1      2      3      4      5      6      7      8      9     10     11     12     13     14     15     16     17     18\n",
            "A:  87.00 167.00 281.00  56.00   8.00 744.00  40.00 107.00 851.00   5.00 333.00  54.00  12.00  56.00 104.00 372.00  82.00 117.00 402.00\n",
            "C: 291.00 145.00  49.00 800.00 903.00  13.00 528.00 433.00  11.00   0.00   3.00  12.00   0.00   8.00 733.00  13.00 482.00 322.00 181.00\n",
            "G:  76.00 414.00 449.00  21.00   0.00  65.00 334.00  48.00  32.00 903.00 566.00 504.00 890.00 775.00   5.00 507.00 307.00  73.00 266.00\n",
            "T: 459.00 187.00 134.00  36.00   2.00  91.00  11.00 324.00  18.00   3.00   9.00 341.00   8.00  71.00  67.00  17.00  37.00 396.00  59.00\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv_layer = model.conv1\n",
        "conv_layer = conv_layer.to(device)\n",
        "\n",
        "max_act_mat = -100 * torch.ones(300)\n"
      ],
      "metadata": {
        "id": "lIhBlgqvjkHF"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_act_mat.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ux2Ncyk9GpnE",
        "outputId": "ac669086-f404-40bd-ca5b-f5d882c91089"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([300])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unfold = torch.nn.Unfold(kernel_size = (19,4), padding = (9,0), stride = 1)\n",
        "\n",
        "with torch.no_grad():\n",
        "  for _, batch in enumerate(tqdm(basset_dataloader_test)):\n",
        "    batch_x = batch[\"sequence\"].to(device)\n",
        "    conv_out = conv_layer(batch_x)\n",
        "    # print(conv_out.shape)\n",
        "    for i in range(300):\n",
        "      max_act_mat[i] = np.maximum(max_act_mat[i],torch.max(conv_out[:,i,:,0]).cpu().detach().numpy())\n",
        "\n",
        "print(max_act_mat.shape)\n",
        "print(max_act_mat)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5bQwLuh6NZj",
        "outputId": "91985bab-aa77-4e27-da97-74585fcd4ad8"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1123/1123 [01:21<00:00, 13.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([300])\n",
            "tensor([4.9700, 4.8929, 4.8372, 4.5354, 4.9796, 4.7282, 4.8245, 4.4463, 4.8523,\n",
            "        4.8572, 4.6083, 5.0555, 5.0254, 4.7123, 4.4172, 5.0435, 5.7545, 4.9731,\n",
            "        4.2831, 5.3378, 4.7958, 4.2009, 5.0374, 5.4140, 4.5781, 4.8891, 4.7411,\n",
            "        4.6867, 4.9395, 4.3737, 4.5427, 4.2368, 4.8394, 4.6089, 4.4521, 4.6637,\n",
            "        4.7382, 5.0788, 5.1028, 5.0574, 5.0675, 4.9962, 5.4123, 4.6317, 5.4619,\n",
            "        4.9343, 4.7872, 4.9316, 5.1589, 4.7506, 4.4100, 4.3558, 4.5409, 4.7757,\n",
            "        5.0973, 5.1993, 4.7863, 4.8345, 4.5571, 4.1687, 5.4508, 5.4500, 4.7653,\n",
            "        4.7747, 5.1056, 4.9593, 4.9124, 4.7413, 5.8432, 4.8026, 4.3194, 4.7410,\n",
            "        5.3293, 4.9093, 4.7543, 4.7217, 4.7356, 5.3756, 4.8163, 5.0583, 4.5049,\n",
            "        5.0095, 5.0922, 5.1565, 5.3730, 5.1228, 5.1545, 5.1919, 5.0479, 4.8696,\n",
            "        5.0396, 5.3449, 4.9375, 5.0782, 4.5718, 5.0748, 4.5006, 5.2899, 5.2331,\n",
            "        4.4156, 5.1286, 4.8962, 4.6013, 5.5388, 5.5039, 4.7675, 5.0292, 4.3501,\n",
            "        5.4168, 4.9573, 5.0045, 5.2493, 4.6435, 5.0178, 5.4273, 5.2519, 4.4927,\n",
            "        5.0407, 5.5956, 5.0774, 4.7478, 4.7678, 4.9560, 5.0957, 4.7336, 5.3907,\n",
            "        5.3437, 4.3922, 4.8602, 5.4377, 5.0040, 4.5450, 4.6904, 4.8887, 4.2741,\n",
            "        4.9745, 5.1173, 5.4940, 5.2881, 4.7090, 5.1309, 5.1282, 5.1603, 5.1623,\n",
            "        5.4961, 5.0425, 5.1140, 4.6164, 4.4672, 5.6263, 5.3436, 5.2996, 5.5840,\n",
            "        4.7339, 5.4618, 4.8436, 4.6564, 4.9919, 4.8667, 5.2010, 5.2079, 4.3815,\n",
            "        5.3647, 4.4172, 4.6267, 5.4861, 4.5036, 5.2858, 4.7552, 5.1732, 4.5573,\n",
            "        5.0991, 5.8201, 5.1752, 4.7877, 5.2179, 4.6877, 4.7879, 4.3946, 4.6772,\n",
            "        5.3641, 4.2221, 4.9895, 5.5901, 5.5133, 5.1678, 5.1879, 4.7797, 4.4872,\n",
            "        5.1978, 4.7903, 4.9254, 4.4785, 4.5196, 4.2323, 5.3526, 4.6082, 4.5372,\n",
            "        4.9647, 4.5912, 5.5391, 4.9031, 4.7646, 4.3345, 5.3250, 4.8732, 4.3797,\n",
            "        4.9926, 5.0363, 5.1705, 5.4526, 4.8883, 5.3946, 4.8993, 5.4584, 4.7516,\n",
            "        5.0658, 5.1867, 5.0605, 4.9673, 5.5076, 5.0003, 5.1601, 4.0438, 5.1456,\n",
            "        4.9192, 5.6912, 5.0478, 5.0258, 4.7735, 4.8840, 5.4381, 5.3697, 4.9253,\n",
            "        5.0077, 5.3757, 4.6757, 4.7792, 5.3389, 4.7667, 4.5967, 4.5084, 5.0726,\n",
            "        4.2111, 5.1912, 4.9448, 5.4222, 4.9991, 4.7006, 4.5704, 4.7674, 4.8048,\n",
            "        4.7537, 5.0933, 5.1240, 4.7476, 4.8252, 4.7433, 5.0613, 4.8186, 5.5451,\n",
            "        4.5317, 5.2276, 4.6227, 5.3607, 5.2847, 5.0898, 4.6635, 4.6540, 5.0480,\n",
            "        4.9872, 4.4640, 5.1671, 4.2371, 5.0884, 5.1951, 4.9403, 6.0243, 4.9484,\n",
            "        5.1501, 4.2167, 5.3230, 4.6456, 5.2940, 5.1217, 4.8155, 5.2322, 5.2669,\n",
            "        5.0025, 5.2163, 5.1859, 5.1324, 5.2705, 5.1720, 5.3720, 5.2285, 5.7654,\n",
            "        4.7376, 4.9308, 4.9046])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaVuQwub8Ap_"
      },
      "source": [
        "\n",
        "4. Next, they counted the base-pair occurrences in the set of sequences that activate the filter to a value that is more than half of its maximum value.\n",
        "\n",
        "  Note: You should use `torch.functional.unfold`."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pwm = torch.zeros(300,19,4)"
      ],
      "metadata": {
        "id": "zvbyHFAIYIXP"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unfold = torch.nn.Unfold(kernel_size = (19,4), padding = (9,0), stride = 1)\n",
        "\n",
        "with torch.no_grad():\n",
        "  for _, batch in enumerate(tqdm(basset_dataloader_test)):\n",
        "    batch_x = batch[\"sequence\"].to(device)\n",
        "    conv_out = conv_layer(batch_x)\n",
        "\n",
        "    print(conv_out.shape)\n",
        "    print(conv_out.squeeze().shape)\n",
        "    print(conv_out.squeeze().permute(0,2,1).shape)\n",
        "    conv_out = conv_out.squeeze().permute(0,2,1).flatten(0,1)\n",
        "    print(conv_out.shape)\n",
        "    \n",
        "    unfold_x = unfold(batch_x)\n",
        "    N,_, L = unfold_x.shape\n",
        "    print(N, L)\n",
        "    unfold_x = unfold_x.reshape(N, 19, 4, L)\n",
        "    print(unfold_x.shape)\n",
        "    print(unfold_x.permute(0,3,1,2).flatten(0,1).shape)\n",
        "    unfold_x = unfold_x.permute(0,3,1,2).flatten(0,1)\n",
        "    max_thresh = max_act_mat.unsqueeze(0).repeat(conv_out.shape[0], 1)\n",
        "    print(max_thresh.shape)\n",
        "    print(max_thresh)\n",
        "    threshold = max_thresh/2\n",
        "    activ_seq = torch.gt(conv_out.cpu(),threshold)\n",
        "    print(activ_seq.shape)\n",
        "\n",
        "    for i in tqdm(range(300)):\n",
        "      inds = activ_seq[:, i]\n",
        "      base_pairs = unfold_x[inds]\n",
        "      pwm_i = base_pairs.sum(dim = 0)\n",
        "      print(pwm_i.shape)\n",
        "      print(pwm_i)\n",
        "      pwm[i, ...] +=pwm_i.cpu()\n",
        "      break\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJiTTADbOnqd",
        "outputId": "918d236f-e3e2-4076-d449-5ebd471f3dd1"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1123 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 300, 600, 1])\n",
            "torch.Size([64, 300, 600])\n",
            "torch.Size([64, 600, 300])\n",
            "torch.Size([38400, 300])\n",
            "64 600\n",
            "torch.Size([64, 19, 4, 600])\n",
            "torch.Size([38400, 19, 4])\n",
            "torch.Size([38400, 300])\n",
            "tensor([[4.9700, 4.8929, 4.8372,  ..., 4.7376, 4.9308, 4.9046],\n",
            "        [4.9700, 4.8929, 4.8372,  ..., 4.7376, 4.9308, 4.9046],\n",
            "        [4.9700, 4.8929, 4.8372,  ..., 4.7376, 4.9308, 4.9046],\n",
            "        ...,\n",
            "        [4.9700, 4.8929, 4.8372,  ..., 4.7376, 4.9308, 4.9046],\n",
            "        [4.9700, 4.8929, 4.8372,  ..., 4.7376, 4.9308, 4.9046],\n",
            "        [4.9700, 4.8929, 4.8372,  ..., 4.7376, 4.9308, 4.9046]])\n",
            "torch.Size([38400, 300])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/300 [00:00<?, ?it/s]\n",
            "  0%|          | 0/1123 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([19, 4])\n",
            "tensor([[229., 159., 115., 337.],\n",
            "        [334., 146.,  46., 316.],\n",
            "        [ 72., 132., 148., 490.],\n",
            "        [283., 145.,  40., 376.],\n",
            "        [ 95., 128., 172., 449.],\n",
            "        [400., 161.,  77., 206.],\n",
            "        [329., 142.,  70., 304.],\n",
            "        [262., 126., 175., 282.],\n",
            "        [345., 114., 184., 202.],\n",
            "        [280.,  31.,  99., 435.],\n",
            "        [312.,  34., 132., 367.],\n",
            "        [267., 165., 127., 286.],\n",
            "        [ 29., 163.,  35., 618.],\n",
            "        [365., 163.,  94., 223.],\n",
            "        [400.,  16., 187., 242.],\n",
            "        [345.,  15., 389.,  96.],\n",
            "        [ 13.,  81., 181., 570.],\n",
            "        [557.,  52.,  97., 139.],\n",
            "        [ 96., 295.,  60., 393.]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pwm_i.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edGPRYIN8us7",
        "outputId": "b56337ca-005c-4085-b5ad-abfaf7109cc3"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([19, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qfh9HcN2Ndo",
        "outputId": "cc2be61e-f24b-4ae3-c082-baa2d27be5b4"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 1, 600, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unfold = torch.nn.Unfold(kernel_size = (19,4), padding = (9,0), stride = 1)\n",
        "\n",
        "with torch.no_grad():\n",
        "  for _, batch in enumerate(tqdm(basset_dataloader_test)):\n",
        "    batch_x = batch[\"sequence\"].to(device)\n",
        "    conv_out = conv_layer(batch_x)\n",
        "    conv_out = conv_out.squeeze().permute(0,2,1).flatten(0,1)\n",
        "    unfold_x = unfold(batch_x)\n",
        "    N,_, L = unfold_x.shape\n",
        "    unfold_x = unfold_x.reshape(N, 19, 4, L)\n",
        "    unfold_x = unfold_x.permute(0,3,1,2).flatten(0,1)\n",
        "    max = max_act_mat.unsqueeze(0).repeat(conv_out.shape[0], 1)\n",
        "    threshold = max/2\n",
        "    activ_seq = torch.gt(conv_out.cpu(),threshold)\n",
        "    for i in range(300):\n",
        "      inds = activ_seq[:, i]\n",
        "      base_pairs = unfold_x[inds]\n",
        "      pwm_i = base_pairs.sum(dim = 0)\n",
        "      pwm[i, ...] +=pwm_i.cpu()\n",
        "      "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qrQCYDjcw-B",
        "outputId": "3961550e-bbeb-45c8-ad11-08ff372a7864"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1123/1123 [03:40<00:00,  5.09it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " pwm.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4akn_Py9dqYc",
        "outputId": "a9379367-2b23-485e-983d-ab9a17c8188e"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([300, 19, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pwm[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_6DsA70kFWw",
        "outputId": "350668a3-e38b-4d4a-ad7d-de4f618bdc73"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[211898., 165819., 104519., 329549.],\n",
              "        [307782., 140395.,  56762., 308141.],\n",
              "        [ 69048., 127682., 158451., 458916.],\n",
              "        [265356., 148346.,  43570., 357644.],\n",
              "        [ 93693., 128739., 178031., 415024.],\n",
              "        [362698., 166875.,  70943., 215457.],\n",
              "        [335356., 147633.,  68880., 264553.],\n",
              "        [238865., 119372., 191304., 267340.],\n",
              "        [338439., 103637., 202578., 172618.],\n",
              "        [261354.,  33685., 113889., 408607.],\n",
              "        [304992.,  43202., 147710., 321631.],\n",
              "        [229362., 155182., 143297., 289694.],\n",
              "        [ 27536., 155303.,  31721., 602975.],\n",
              "        [332249., 167460.,  87462., 230297.],\n",
              "        [405881.,  11106., 209228., 191166.],\n",
              "        [319891.,  14111., 377345., 105848.],\n",
              "        [  7032.,  74600., 208048., 527080.],\n",
              "        [516857.,  56215., 116696., 126097.],\n",
              "        [ 89466., 312913.,  50735., 361602.]])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pwm[i,:,:].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bYWlliNh4Ax",
        "outputId": "c3fdfe82-6f5e-4c9d-c626-9fe4f4c4142b"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([19, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIClN1pr8rc-"
      },
      "source": [
        "5. Given your 300 PWMs derived from your convolution filters, check to see if any of them are similar to the PWM for CTCF. You could quantify the similarity using *Pearson Correlation Coefficient*. Make a visualization of the PWM of the CTCF motif along with the most similar ones learned from the network. "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats as stats"
      ],
      "metadata": {
        "id": "IjRXekQciDBQ"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pwm_ctcf_dict = dict(pwm_ctcf)"
      ],
      "metadata": {
        "id": "OHBzmcxmit3K"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pwm_ctcf_arr = list(pwm_ctcf_dict.values())\n",
        "pwm_ctcf_arr = np.array(pwm_ctcf_arr).T"
      ],
      "metadata": {
        "id": "AjTJLlZipWM-"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pwm_ctcf_arr.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlNAZ3RqpzXB",
        "outputId": "cb60756a-3f6e-4007-db15-c9eee28788b4"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(19, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "flat_ctcf = pwm_ctcf_arr.flatten()\n",
        "flat_ctcf.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01zCad45rhpk",
        "outputId": "00d3e3c6-1f24-4633-e7a7-d489081e4858"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(76,)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "similarity_scores = []\n",
        "for i in tqdm(range(300)):\n",
        "  filter_pwm_norm = pwm[i,:,:]\n",
        "  filter_pwm_norm /=  filter_pwm_norm.sum(axis=1)[:,np.newaxis]\n",
        "  flat_filter = filter_pwm_norm.flatten()\n",
        "  sim = stats.pearsonr(flat_ctcf, flat_filter)\n",
        "  similarity_scores.append(sim)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gd25-XZii-oL",
        "outputId": "60eea3d0-fe13-472e-ab4b-9eed94dbd0ff"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300/300 [00:00<00:00, 5611.81it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max(similarity_scores)"
      ],
      "metadata": {
        "id": "cNagtNXtFTIs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c946524-a99a-4ebc-8dad-25e0b897399a"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.7806102739969752, 9.244477685536505e-17)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "similarity_scores = [x[0] for x in similarity_scores]\n",
        "max(similarity_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkA4rHH911FZ",
        "outputId": "fbb81f48-f84d-4e55-dedd-8893ed07a2bc"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7806102739969752"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "most_sim_ind = similarity_scores.index(max(similarity_scores))\n",
        "most_sim_conv_pwm = pwm[most_sim_ind, :,:]\n",
        "most_sim_conv_pwm.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DsCbhuyFPm3r",
        "outputId": "69c734cd-7486-4538-b9e9-73b620d0094b"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([19, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(set(similarity_scores))"
      ],
      "metadata": {
        "id": "3ANTr-jo18n3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.hist(similarity_scores, 300)"
      ],
      "metadata": {
        "id": "ovYU2uua1VBo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.isnan(similarity_scores).any()"
      ],
      "metadata": {
        "id": "O5B3FdYoMGJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_2_score = sorted(similarity_scores)[-2]\n",
        "print(top_2_score)\n",
        "second_sim_ind = similarity_scores.index(top_2_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-ZfSHs30B7y",
        "outputId": "38721715-ea47-4d9b-8870-fe1e84d9d39c"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5874470076599283\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "most_sim_conv_pwm_2 = pwm[second_sim_ind, :, :]"
      ],
      "metadata": {
        "id": "nbtvz5XQ0PQy"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fancy Sequence PLOTS"
      ],
      "metadata": {
        "id": "R_txcPrzLYSz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n"
      ],
      "metadata": {
        "id": "dnc_pO6kZc1P"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "most_sim_conv_pwm = most_sim_conv_pwm.numpy"
      ],
      "metadata": {
        "id": "nmTTJeXSv6_1"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "most_sim_conv_pwm.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yZfsaX2wHFR",
        "outputId": "efa6be52-48ec-4dcb-c9d3-c910a99841f4"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(19, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "alphabets = [\"A\", \"C\", \"G\", \"T\"]"
      ],
      "metadata": {
        "id": "qpraiePkcwva"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "ax = sns.heatmap(most_sim_conv_pwm.T, \n",
        "                 yticklabels = alphabets,\n",
        "                 cbar_kws={\"orientation\": \"horizontal\"},\n",
        "                 cmap=\"YlGnBu\") \n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "id": "-gc7caK6ZS3p",
        "outputId": "339345f0-e5ff-4c8a-8dae-bffa3106909a"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ax = sns.heatmap(pwm_ctcf_arr.T, \n",
        "                 yticklabels = alphabets,\n",
        "                 cbar_kws={\"orientation\": \"horizontal\"},\n",
        "                 cmap=\"YlGnBu\") \n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "id": "ZfFrHRLzaOlz",
        "outputId": "a26d0c12-0492-4ec8-efda-4fd884038813"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAADoCAYAAADPPA7+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAATfUlEQVR4nO3deZAkZZnH8e/DDMMx3OcCgw4io7DoAiLBpRzDGsAio3gEHhEQCrOy4sohLkqsgRJGrKKu/7i4I4iGCIIXoqigMngzOBzDDSJyDAKDiLByzkw/+0dlT1c3fVRlZVf3i99PRMVkZlU++dRb2b/OyqqejMxEklSOtaa6AUlSdwxuSSqMwS1JhTG4JakwBrckFWbmZG/gyZU/7flrKyueeaaJVrj20bUbqXPU3I17rrHOjE0a6ATmveE3Pde49cf/1EAn8NTKhxup88rdft5zjYdvP66BTuCTNzzQSJ0PvXp2zzVmrdX7fgfw/MATPdd4dvXjDXQCH7tuvUbqfHLPgZ5rPL/6qQY6gQ8uaeZ1uuCAA2Ks+zzilqTCGNySVBiDW5IKY3BLUmEMbkkqjMEtSYUxuCWpMAa3JBXG4JakwhjcklQYg1uSCmNwS1JhDG5JKozBLUmFMbglqTAGtyQVxuCWpMJ0HdwRsX9EfGEympEkTayj4I6I3SPi7Ii4FzgLuGOCxy+MiKURsfT8cy9voE1J0qAxrzkZEfOAd1S3PwMXA5GZB01UNDMXAYugmWtOSpKGjHex4DuAXwJHZObdABFxcl+6kiSNabxTJUcBDwGLI+JLETEfGPOqw5Kk/hgzuDPz0sw8GnglsBg4CdgqIs6JiDf0q0FJ0nATfjiZmU9l5oWZ+UZgDnAD8B+T3pkkaVRdfR0wMx/PzEWZOX+yGpIkjc8/wJGkwhjcklQYg1uSCmNwS1JhDG5JKozBLUmFMbglqTAGtyQVxuCWpMIY3JJUGINbkgpjcEtSYSJzci9Qc/5dV/S8gUO2e76JVthq3a0bqbPLXr/pucafHl3SQCfw1H3/2XONXc//cwOdwI7bN/PftX/vkM17rrFWjHeNkP4byFU912jqOSWre64x77DfNtAJ3PnDvRups8+3/9JzjbfMe6aBTuCNL3mukTo7b3LEmD9QHnFLUmEMbkkqjMEtSYUxuCWpMAa3JBXG4JakwhjcklQYg1uSCmNwS1JhDG5JKozBLUmFMbglqTAGtyQVxuCWpMIY3JJUGINbkgpjcEtSYcYN7oh4eUTsN8ry/SJix8lrS5I0lomOuD8PPDnK8ier+0YVEQsjYmlELL364h/20p8kaYSJLmK3dWbePHJhZt4cEXPHWikzFwGLoJlrTkqShkx0xL3JOPet12QjkqTOTBTcSyPi+JELI+I44LrJaUmSNJ6JTpWcBHw3It7FUFDvCcwC3jyZjUmSRjducGfmI8C+EXEQsGu1+PLMvGrSO5MkjWqiI24AMnMxsHiSe5EkdcA/wJGkwhjcklQYg1uSCmNwS1JhDG5JKozBLUmFMbglqTAGtyQVxuCWpMIY3JJUGINbkgpjcEtSYTr6T6Z68bYd1um5xnt+1cw1Gx57dmUjde5aekjPNWbE4Q10Ak+veqTnGu/c/fkGOoHTXr1RI3VW53M915j90rMa6AS2PPV9jdTZYsvej5Hu+ui5DXQC2267T8817vrNQQ10ArtdsKKROsft8UzPNd4zr/esArhy+apG6uw8zmVsPOKWpMIY3JJUGINbkgpjcEtSYQxuSSqMwS1JhTG4JakwBrckFcbglqTCGNySVBiDW5IKY3BLUmEMbkkqjMEtSYUxuCWpMAa3JBXG4Jakwowb3BGxICLe3za/JCLuqW5vnfz2JEkjTXTE/WHgsrb5dYDXAgcCJ4y1UkQsjIilEbH0y+d+v+cmJUlDJrrm5KzMfKBt/leZ+RjwWETMHmulzFwELAL428qrs/c2JUmDJjri3rR9JjNPbJvdsvl2JEkTmSi4l0TE8SMXRsS/AtdOTkuSpPFMdKrkZODSiHgncH217DW0znW/aTIbkySNbtzgzswVwL4RcTDwj9XiyzPzqknvTJI0qomOuAGogtqwlqRpwD/AkaTCGNySVBiDW5IKY3BLUmEMbkkqjMEtSYUxuCWpMAa3JBXG4JakwhjcklQYg1uSCmNwS1JhInNyL1Bz4OW/7nkD/7Pf4020wmbrDDRUZ7uea8xaa8MGOoEnV97Xc40NZvb+fAA+c/ODjdQ59VXb9FxjRsxqoBNIVjdS58zrex+bM/do5nV6etWKBqpEAzVgvRmbN1JnVT7bc42Fv/pbA53AOfuu3Uid9WbuO+Yge8QtSYUxuCWpMAa3JBXG4JakwhjcklQYg1uSCmNwS1JhDG5JKozBLUmFMbglqTAGtyQVxuCWpMIY3JJUGINbkgpjcEtSYcYM7oiY2c9GJEmdGe+I+9q+dSFJ6th4wd3MJS4kSY0a73TIlhFxylh3ZubnxrovIhYCCwF2OvE0tj10Qf0OJUnDjBfcM4ANqHHknZmLgEXQzDUnJUlDxgvuhzLzE33rRJLUEc9xS1Jhxgvu+X3rQpLUsTGDOzP/0s9GJEmd8S8nJakwBrckFcbglqTCGNySVBiDW5IKY3BLUmEMbkkqjMEtSYUxuCWpMAa3JBXG4JakwhjcklQYg1uSSpOZU34DFk6XOvbic7KX6VVnOvUyXZ7TdDniXjiN6tjL5NaZTr00VcdeJrfOdOqlqTo91ZguwS1J6pDBLUmFmS7BvWga1bGXya0znXppqo69TG6d6dRLU3V6qhHViXJJUiGmyxG3JKlDBrckFWbKgzsiDo2IOyPi7og4vWaNL0fEioi4pYc+to+IxRFxW0TcGhEfrFFj3Yi4NiKWVTU+Xrefqt6MiLghIn7QQ417I+LmiLgxIpbWrLFJRHwrIu6IiNsjYp8aNV5R9TB4ezIiTqpR5+RqbG+JiIsiYt1ua1R1PljVuLWbPkbb1yJis4j4SUT8vvp305p13lb1MxARe9ascXb1Ot0UEd+NiE1q1jmrqnFjRFwZEdvWqdN236kRkRGxRY1ezoyIB9v2ncPr9hIRH6jG59aI+HSNXi5u6+PeiLixTi8RsVtEXDP4cxkRe01UZ5gmvpDew5fQZwB/AF4GzAKWAbvUqPN6YA/glh562QbYo5reELir216AADaoptcGlgB799DTKcCFwA96qHEvsEWPr9NXgeOq6VnAJg287g8DL+1yve2APwLrVfOXAMfW2P6uwC3A+sBM4KfAy+vua8CngdOr6dOBT9WsszPwCuBqYM+aNd4AzKymP9VDLxu1Tf878MU6darl2wNXAPdNtC+O0cuZwIe6fI1Hq3NQ9VqvU81vVef5tN3/WeBjNXu5Ejismj4cuLqb5zfVR9x7AXdn5j2Z+TzwDWBBt0Uy8xfAX3ppJDMfyszrq+n/A26nFRTd1MjM/Fs1u3Z1q/Xpb0TMAf4FOLfO+k2JiI1p7XjnAWTm85n51x7Lzgf+kJn31Vh3JrBeRMykFbx/qlFjZ2BJZj6dmauAnwNHdbLiGPvaAlq/3Kj+fVOdOpl5e2be2Ukf49S4snpOANcAc2rWebJtdjYd7Mfj/Bz+N/DhHmt0ZYw6JwD/lZnPVY9ZUbeXiAjg7cBFNXtJYKNqemO63I+nOri3Ax5om19Ol2E5GSJiLrA7rSPmbtedUb19WgH8JDO7rlH5PK2dfaDm+oMSuDIirouIOn+ttQPwKHB+ddrm3IiY3WNPR9PBDj9SZj4IfAa4H3gIeCIzr6yx/VuA10XE5hGxPq0jnu1r1Bm0dWY+VE0/DGzdQ60mvQf4Ud2VI+KTEfEA8C7gYzVrLAAezMxldfuonFiduvlyJ6eixjCP1uu+JCJ+HhGv7aGf1wGPZObva65/EnB2Nb6fAT7SzcpTHdzTTkRsAHwbOGnEUUdHMnN1Zu5G60hnr4jYtUYPRwArMvO6btcdxf6ZuQdwGPD+iHh9l+vPpPU275zM3B14itbpgFoiYhZwJPDNGutuSuvodgdgW2B2RLy72zqZeTut0whXAj8GbgRWd1tnjNpJzXdZTYqIM4BVwNfr1sjMMzJz+6rGiTV6WB/4KDVDv805wI7AbrR+YX+2Zp2ZwGbA3sBpwCXVkXMd76DGwUebE4CTq/E9meodbaemOrgfZPiRzpxq2ZSIiLVphfbXM/M7vdSqTicsBg6tsfp+wJERcS+t00cHR8QFNft4sPp3BfBdWqenurEcWN72zuFbtIK8rsOA6zPzkRrrHgL8MTMfzcyVwHeAfes0kZnnZeZrMvP1wOO0PtOo65GI2Aag+nfct+CTLSKOBY4A3lX9IunV14G31FhvR1q/ZJdV+/Ic4PqI+IduimTmI9UB0QDwJbrfhwctB75TndK8lta72XE/LB1NdZruKODimn0AHENr/4XWQUxXz2mqg/t3wE4RsUN1JHY0cNlUNFL95j0PuD0zP1ezxpaDn+JHxHrAPwN3dFsnMz+SmXMycy6tMbkqM7s+soyI2RGx4eA0rQ+uuvrmTWY+DDwQEa+oFs0Hbuu2lza9HKncD+wdEetXr9d8Wp9FdC0itqr+fQmtH8ILa/YErX32mGr6GOB7PdTqSUQcSusU25GZ+XQPdXZqm11Avf345szcKjPnVvvyclpfAHi4y162aZt9M13uw20upfUBJRExj9YH7X+uUecQ4I7MXF6zD2id0z6gmj4Y6O6USzefZE7Gjdb5xbtofbvkjJo1LqL1FmolrZ3jvTVq7E/rLe5NtN463wgc3mWNVwM3VDVuoYNPnDuoeSA1v1VC69s6y6rbrT2M727A0up5XQpsWrPObOAxYOMexuPjtELkFuBrVN8QqFHnl7R+AS0D5veyrwGbAz+rfvh+CmxWs86bq+nngEeAK2rUuJvW50aD+3An3wYZrc63qzG+Cfg+sF2dOiPuv5eJv1UyWi9fA26uerkM2Kbmc5oFXFA9r+uBg+s8H+ArwPt63Gf2B66r9r8lwGu62X/9k3dJKsxUnyqRJHXJ4JakwhjcklQYg1uSCmNwS1JhDG5JKozBLUmFMbglqTAGtyQVxuCWpMIY3JJUGINbkgpjcEtSYQxuSSqMwS1JhTG4JakwMyd/E3dlkgxerLx14YYk11xPdaB1VQeGrrGaDLQes+YiD7lm2WCNYTWrdVuPH1o2rGYOjNhukjkwYp62rUBmazozqkfAQI52/+Az6WCdtsfQdt9gjcF1B16wbOhy7wM5eGttY/Xg/Jr7Y2hZDq2zOmPY/ACtZcNr0laz9fjVw7YbIx7Tvo1gNcO3OVA9l8FlWa0/MLLmGM9tYJTtti9rn8/258Lwvl6wTg6u0/ZaJmv2uUzIgbbXNtsfU60zkMPmB0bev6ZGDtvGsO0OjFxnRM3BHXJoAInBnWZgxIarQYzBjbStM2yHGhilxpp1RtRo37mHzScxuP6aGm112ubjBfczYtBH9NE2Hy+4f/RttP+QxcjnO2K+9XM/0Pa6DMCaZQMjHjOUW4PL1tyfAzBifs3jB/Nl2LLh82uyb4xtPnP/RWNeyNgjbkkqjMEtSYUxuCWpMAa3JBXG4JakwhjcklQYg1uSCmNwS1JhDG5JKozBLUmFMbglqTAGtyQVxuCWpMIY3JJUGINbkgpjcEtSYWLoYgWTtIGIhZm5aFI3UhDHY4hjMZzjMcSxGF8/jrgX9mEbJXE8hjgWwzkeQxyLcXiqRJIKY3BLUmH6EdyepxrO8RjiWAzneAxxLMYx6R9OSpKa5akSSSqMwS1JhWksuCPi0Ii4MyLujojTR7l/nYi4uLp/SUTMbWrb000HY3FKRNwWETdFxM8i4qVT0We/TDQebY97S0RkROzZz/76rZPxiIi3V/vIrRFxYb977JcOflZeEhGLI+KG6ufl8Knoc9rJzJ5vwAzgD8DLgFnAMmCXEY/5N+CL1fTRwMVNbHu63Toci4OA9avpE16sY9HpeFSP2xD4BXANsOdU9z3F+8dOwA3AptX8VlPd9xSOxSLghGp6F+Deqe57OtyaOuLeC7g7M+/JzOeBbwALRjxmAfDVavpbwPyIiIa2P51MOBaZuTgzn65mrwHm9LnHfupk3wA4C/gU8Gw/m5sCnYzH8cAXMvNxgMxc0ece+6WTsUhgo2p6Y+BPfexv2moquLcDHmibX14tG/UxmbkKeALYvKHtTyedjEW79wI/mtSOptaE4xERewDbZ+bl/WxsinSyf8wD5kXEryPimog4tG/d9VcnY3Em8O6IWA78EPhAf1qb3mZOdQN/zyLi3cCewAFT3ctUiYi1gM8Bx05xK9PJTFqnSw6k9W7sFxHxqsz865R2NTXeAXwlMz8bEfsAX4uIXTNzYKobm0pNHXE/CGzfNj+nWjbqYyJiJq23PY81tP3ppJOxICIOAc4AjszM5/rU21SYaDw2BHYFro6Ie4G9gctexB9QdrJ/LAcuy8yVmflH4C5aQf5i08lYvBe4BCAzfwusC2zRl+6msaaC+3fAThGxQ0TMovXh42UjHnMZcEw1/Vbgqqw+cXiRmXAsImJ34H9phfaL9fzloHHHIzOfyMwtMnNuZs6ldc7/yMxcOjXtTrpOflYupXW0TURsQevUyT39bLJPOhmL+4H5ABGxM63gfrSvXU5DjQR3dc76ROAK4Hbgksy8NSI+ERFHVg87D9g8Iu4GTgHG/FpYyToci7OBDYBvRsSNETFyZ33R6HA8/m50OB5XAI9FxG3AYuC0zHzRvTvtcCxOBY6PiGXARcCxL9IDvq74J++SVBj/clKSCmNwS1JhDG5JKozBLUmFMbglqTAGtyQVxuCWpML8P/SnnJbdHlQ8AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ax = sns.heatmap(most_sim_conv_pwm_2.T, \n",
        "                 yticklabels = alphabets,\n",
        "                 cbar_kws={\"orientation\": \"horizontal\"},\n",
        "                 cmap=\"YlGnBu\") \n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "id": "8lgedMJs0d6b",
        "outputId": "0860485f-8d50-4ab6-ee7d-63ee87b00495"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "ax = sns.heatmap(most_sim_conv_pwm.T) # linewidth=0.5)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vscOT7phaJjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del max"
      ],
      "metadata": {
        "id": "43ufZ7zZlho0"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "cQod4BSVvAkl"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Copy_of_main_EN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}